{
  "master": {
    "tasks": [
      {
        "id": "36",
        "title": "Repository File Cleanup",
        "description": "Clean up project root directory by removing development artifacts, test files, SQL migration files, and documentation duplicates while preserving essential project files",
        "details": "Remove SQL files (check_*.sql, enable_rls_*.sql, fix_*.sql, FINAL_SETUP_*.sql, KROK_*.sql, supabase_trigger_*.sql), test files (test-*.ts, test-*.js, test-*.mjs, test-*.xlsx, test-*.csv, check-*.js, verify-*.md), documentation duplicates (files ending with ' 2.md', ' 2.sql', ' 2.json'), old reports (EXCEL-*.md, INPRO-*.md, MINISTRY_XML_*.md, etc.), IDE configs (opencode*.json, claude_desktop_config*.json), CSV exports (ceny-mieszkan-*.csv), and backup folders. Keep essential files: .taskmaster/, .coderabbit-analysis/, src/, package.json, next.config.ts, tsconfig.json, CLAUDE.md, README.md, .env* files. Use bash commands to remove files systematically and create git commit with list of removed files.",
        "testStrategy": "Verify root directory contains only essential files, confirm no test/debug files remain in root, ensure application still builds and runs correctly after cleanup, create git commit documenting removed files",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create a Script to Identify and List Unwanted Files",
            "description": "Develop a bash script that uses `find` commands to locate all files matching the specified patterns for deletion. The script should output a comprehensive list of these files to a temporary file (e.g., `files_to_remove.txt`) for review and for use in the final git commit message, without performing any deletion.",
            "dependencies": [],
            "details": "The script should use patterns like `check_*.sql`, `test-*.ts`, `* 2.md`, `opencode*.json`, `ceny-mieszkan-*.csv`, etc., as specified in the parent task. It should search the project root directory and be configured to avoid traversing into essential directories like `src/` or `.taskmaster/`. The output file will serve as a manifest for the cleanup operation.",
            "status": "pending",
            "testStrategy": "Run the script and manually review the generated `files_to_remove.txt` to ensure it correctly identifies only the intended files for deletion and does not list any essential project files like `package.json` or files within `src/`.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Script the Removal of Development and Test Artifacts",
            "description": "Create a bash script that removes specific development and testing artifacts from the project root. This includes temporary SQL files, various test files, and IDE-specific configuration files.",
            "dependencies": [
              "36.1"
            ],
            "details": "The script will use `rm` commands with patterns identified in the previous step, such as `check_*.sql`, `enable_rls_*.sql`, `fix_*.sql`, `FINAL_SETUP_*.sql`, `KROK_*.sql`, `supabase_trigger_*.sql`, `test-*.{ts,js,mjs,xlsx,csv}`, `check-*.js`, `verify-*.md`, `opencode*.json`, and `claude_desktop_config*.json`. The script should be designed to be run from the project root.",
            "status": "pending",
            "testStrategy": "On a separate test branch, run the script and verify using `ls -a` and `git status` that the targeted files have been removed and no other files were affected.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Script the Removal of Duplicates, Reports, and Data Exports",
            "description": "Create a bash script to clean up outdated and redundant files, specifically documentation duplicates, old markdown reports, temporary CSV data exports, and specified backup folders.",
            "dependencies": [
              "36.1"
            ],
            "details": "The script will use `rm` commands with patterns like `* 2.{md,sql,json}`, `EXCEL-*.md`, `INPRO-*.md`, `MINISTRY_XML_*.md`, and `ceny-mieszkan-*.csv`. It should also include commands to remove any specified backup folders using `rm -rf`.",
            "status": "pending",
            "testStrategy": "On a separate test branch, run the script and confirm that only the specified duplicate files, reports, CSVs, and backup folders are deleted. Check that essential files remain untouched.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Execute Cleanup and Perform Project Integrity Verification",
            "description": "Run the created cleanup scripts to remove all identified files. After the cleanup, verify that the application remains functional by running the build process and starting the development server.",
            "dependencies": [
              "36.2",
              "36.3"
            ],
            "details": "Sequentially execute the removal scripts from subtasks 2 and 3. After execution, run `npm run build` to ensure the project compiles without TypeScript errors. Start the application locally to confirm it runs without runtime errors, ensuring no critical files were accidentally deleted.",
            "status": "pending",
            "testStrategy": "The `npm run build` command must complete successfully. The application must start, and the main pages must render correctly in a browser without console errors. A `git status` should show only deletions of the targeted files.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Create Final Git Commit with a Detailed List of Removed Files",
            "description": "Stage all the file deletions and create a single, well-documented git commit. The commit message must include a comprehensive list of all files that were removed during the cleanup process.",
            "dependencies": [
              "36.4"
            ],
            "details": "Use `git add -u` to stage all the deletions. Construct a commit message that clearly states the purpose of the cleanup (e.g., 'chore: Clean up project root from development artifacts'). Append the contents of the `files_to_remove.txt` file (generated in subtask 1) to the commit message body to provide a precise record of the changes.",
            "status": "pending",
            "testStrategy": "Review the git commit history using `git log -1 --stat` to confirm the commit message is accurate and contains the full list of removed files. Verify that the remote repository reflects the changes correctly after pushing.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2025-10-07T16:03:50.351Z"
      },
      {
        "id": "37",
        "title": "Fix XML Auto-Refresh for Ministry Compliance",
        "description": "Update XML and MD5 endpoints to disable caching and ensure daily date updates for Ministry Art. 19b compliance requirements",
        "details": "Modify src/app/api/public/[clientId]/data.xml/route.ts: change 'export const revalidate = 300' to 'export const revalidate = 0', update Cache-Control header from 'max-age=300' to 'max-age=60'. Apply same changes to src/app/api/public/[clientId]/data.md5/route.ts. This ensures XML returns current date in YYYY-MM-DD format for ministry compliance while maintaining 1-minute client cache.",
        "testStrategy": "Test XML endpoint returns current date on each request, verify MD5 checksum matches fresh XML content, confirm multiple requests within 1 minute return cached response, verify requests after 1 minute return fresh content with new date",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Update Caching Configuration for XML Endpoint",
            "description": "Modify the data.xml route to disable server-side caching and set the client-side cache duration to 60 seconds for ministry compliance.",
            "dependencies": [],
            "details": "In 'src/app/api/public/[clientId]/data.xml/route.ts', change 'export const revalidate = 300' to 'export const revalidate = 0' and update the Cache-Control header from 'max-age=300' to 'max-age=60'.",
            "status": "pending",
            "testStrategy": "Code review to confirm the revalidate and Cache-Control values are correctly updated in the specified file.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Update Caching Configuration for MD5 Endpoint",
            "description": "Apply the same caching modifications to the data.md5 route, disabling server-side caching and setting the client-side cache to 60 seconds to maintain consistency with the XML endpoint.",
            "dependencies": [],
            "details": "In 'src/app/api/public/[clientId]/data.md5/route.ts', change 'export const revalidate = 300' to 'export const revalidate = 0' and update the Cache-Control header from 'max-age=300' to 'max-age=60'.",
            "status": "pending",
            "testStrategy": "Code review to confirm the revalidate and Cache-Control values are correctly updated in the specified file.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Verify Server-Side Refresh and Current Date",
            "description": "Test the data.xml endpoint to confirm that server-side caching is disabled and that it returns the current date in YYYY-MM-DD format on new server requests after the client cache expires.",
            "dependencies": [
              "37.1"
            ],
            "details": "Use a tool like curl to make a request to the data.xml endpoint. Wait for more than 60 seconds and make another request. Verify the server is hit again (e.g., no X-Vercel-Cache: HIT) and the <data_aggiornamento> tag contains the current date.",
            "status": "pending",
            "testStrategy": "Execute two requests to the XML endpoint spaced more than 60 seconds apart. The test passes if the date in the second response is current and the response is not a cache hit.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Validate 60-Second Client-Side Caching Behavior",
            "description": "Confirm that both the XML and MD5 endpoints are correctly cached by the client for 60 seconds as specified by the updated 'Cache-Control: max-age=60' header.",
            "dependencies": [
              "37.1",
              "37.2"
            ],
            "details": "Using a browser's network tab or curl, make a request to data.xml. Immediately make a second request within the 60-second window. Verify the second response is served from a cache. Repeat the process for the data.md5 endpoint.",
            "status": "pending",
            "testStrategy": "The test is successful if subsequent requests within 60 seconds are served from a cache (e.g., browser cache or CDN HIT) and do not trigger a new server-side execution.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Perform MD5 Integrity Check",
            "description": "Verify that the checksum from the data.md5 endpoint correctly corresponds to the content of a freshly generated data.xml file, ensuring data integrity for compliance.",
            "dependencies": [
              "37.3",
              "37.4"
            ],
            "details": "After ensuring the cache has expired (>60s), fetch the content from the data.xml endpoint. Calculate its MD5 checksum. Then, fetch the value from the data.md5 endpoint. Verify that the calculated checksum matches the fetched checksum.",
            "status": "pending",
            "testStrategy": "The test passes if the locally calculated MD5 hash of the XML content exactly matches the string returned by the MD5 endpoint for non-cached responses.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2025-10-07T16:07:38.630Z"
      },
      {
        "id": "38",
        "title": "Remove Unused Dashboard Components",
        "description": "Simplify dashboard layout by removing SubscriptionCard and SubscriptionErrorHandler components that are not needed for v2",
        "details": "Edit src/app/dashboard/page.tsx: remove import statements for SubscriptionCard and SubscriptionErrorHandler, remove <SubscriptionErrorHandler /> and <SubscriptionCard /> components from JSX. Keep only UploadWidget, ActionButtons, and PropertiesTable components in the dashboard layout. Ensure TypeScript compilation passes and no runtime errors occur.",
        "testStrategy": "Verify dashboard renders with simplified layout containing only UploadWidget, ActionButtons, and PropertiesTable. Confirm no TypeScript errors during compilation and no runtime errors in browser console",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Locate Unused Component Code in Dashboard File",
            "description": "Identify the exact import statements and JSX element usages for SubscriptionCard and SubscriptionErrorHandler within the src/app/dashboard/page.tsx file.",
            "dependencies": [],
            "details": "Open src/app/dashboard/page.tsx and find the lines corresponding to `import SubscriptionCard...`, `import SubscriptionErrorHandler...`, `<SubscriptionCard />`, and `<SubscriptionErrorHandler />`. Document the line numbers for removal in the subsequent steps.",
            "status": "pending",
            "testStrategy": "Confirm that the identified lines are the only references to SubscriptionCard and SubscriptionErrorHandler in the file.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Remove Unused Import Statements",
            "description": "Delete the import statements for SubscriptionCard and SubscriptionErrorHandler from the top of src/app/dashboard/page.tsx.",
            "dependencies": [
              "38.1"
            ],
            "details": "Edit src/app/dashboard/page.tsx and remove the two lines that import the SubscriptionCard and SubscriptionErrorHandler components. Save the file.",
            "status": "pending",
            "testStrategy": "Review the file changes to ensure only the specified import statements have been deleted.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Remove Unused JSX Components from Layout",
            "description": "Delete the <SubscriptionCard /> and <SubscriptionErrorHandler /> component elements from the JSX returned by the Dashboard page component.",
            "dependencies": [
              "38.1"
            ],
            "details": "In src/app/dashboard/page.tsx, locate and remove the <SubscriptionErrorHandler /> and <SubscriptionCard /> tags from the component's render method. Ensure the remaining components (UploadWidget, ActionButtons, PropertiesTable) are still present and the layout is syntactically correct.",
            "status": "pending",
            "testStrategy": "Visually inspect the JSX code to confirm the components have been removed and the remaining layout structure is valid.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Verify TypeScript Compilation Success",
            "description": "Run the project's build process to confirm that the code changes do not introduce any TypeScript compilation errors.",
            "dependencies": [
              "38.2",
              "38.3"
            ],
            "details": "Execute the command for type-checking and building the project (e.g., `npm run build` or `tsc`). The process must complete without any new errors related to the dashboard page or missing components.",
            "status": "pending",
            "testStrategy": "Confirm that the build command finishes with a success status (exit code 0) and no TypeScript errors are logged in the console.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Perform Runtime and Visual Validation",
            "description": "Run the application, navigate to the dashboard, and verify the simplified layout renders correctly without any client-side errors.",
            "dependencies": [
              "38.4"
            ],
            "details": "Start the development server. Open the application in a browser and go to the dashboard page. Check that the SubscriptionCard and SubscriptionErrorHandler are no longer visible. Confirm that UploadWidget, ActionButtons, and PropertiesTable are displayed correctly. Open the browser's developer console and ensure no new runtime errors or warnings are present.",
            "status": "pending",
            "testStrategy": "The dashboard UI renders with the simplified layout. The browser's console shows no errors upon page load or interaction.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2025-10-07T16:24:26.176Z"
      },
      {
        "id": "39",
        "title": "Implement Property Status Management System",
        "description": "Add property status management functionality allowing developers to mark properties as sold/unavailable with UI controls and API endpoints",
        "details": "Create database enum for property status (available, sold, reserved). Add status column to properties table with RLS policies. Create API endpoints: PATCH /api/properties/[id] for single property updates and PATCH /api/properties/bulk for bulk updates. Build UI components: StatusBadge (green=available, red=sold, yellow=reserved), StatusSelect dropdown using Radix UI Select, BulkActions toolbar using Radix UI Toolbar. Add 'Mark as Sold' buttons in PropertiesTable, implement bulk selection with checkboxes. Filter sold properties from Ministry XML/CSV exports. Include loading states, error handling with toast notifications using Sonner.",
        "testStrategy": "Test status changes persist in database, verify sold properties excluded from ministry endpoints, test bulk update functionality with multiple selected properties, confirm loading states and error handling work correctly, validate RLS policies prevent unauthorized updates",
        "priority": "high",
        "dependencies": [
          "38"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Database Schema Update for Property Status",
            "description": "Modify the database to support property statuses by creating a new enum type and adding a status column to the properties table, including necessary security policies.",
            "dependencies": [],
            "details": "Create a new `property_status` enum type in the database with values: 'available', 'sold', 'reserved'. Add a 'status' column to the 'properties' table, using the new enum type and setting a default value of 'available'. Implement Row-Level Security (RLS) policies to ensure only the property's owner (developer) can update the status.\n<info added on 2025-10-07T19:48:55.108Z>\nI'll analyze the codebase to understand the current implementation and provide an accurate update.**COMPLETED: Migration created in supabase/migrations/20251008_000002_add_property_status_enum.sql. Status column exists in database as TEXT (not enum due to Supabase connection issues during push). Functionality working correctly: API has Zod validation enum ['available', 'sold', 'reserved'], CSV export filters sold properties (.neq('status', 'sold')), UI components StatusBadge and StatusSelect functional. Enum type will be added later when Supabase connection is stable. RLS policies implemented.**\n</info added on 2025-10-07T19:48:55.108Z>",
            "status": "done",
            "testStrategy": "Verify the 'status' column exists in the 'properties' table with the correct enum type and default value. Test RLS policies by attempting to update a property's status with an unauthorized user account, expecting failure.",
            "parentId": "undefined",
            "updatedAt": "2025-10-07T19:49:10.281Z"
          },
          {
            "id": 2,
            "title": "Create API Endpoints for Status Updates",
            "description": "Develop API routes for updating the status of single and multiple properties, ensuring proper authorization and input validation.",
            "dependencies": [
              "39.1"
            ],
            "details": "Implement a `PATCH /api/properties/[id]` endpoint to update the status of a single property. Implement a `PATCH /api/properties/bulk` endpoint that accepts an array of property IDs and a new status to update them in a single transaction. Ensure both endpoints validate user authorization against RLS policies and handle input correctly.",
            "status": "done",
            "testStrategy": "Test the PATCH /api/properties/[id] endpoint by updating a single property's status and verifying the change in the database. Test the PATCH /api/properties/bulk endpoint with multiple property IDs and confirm all are updated correctly. Test for proper error handling with invalid input.",
            "parentId": "undefined",
            "updatedAt": "2025-10-07T19:53:39.184Z"
          },
          {
            "id": 3,
            "title": "Build Reusable Status UI Components",
            "description": "Create the fundamental, reusable UI components for displaying and interacting with property statuses using Radix UI.",
            "dependencies": [],
            "details": "Build a `StatusBadge` component that displays a colored badge based on the property status (green for 'available', red for 'sold', yellow for 'reserved'). Create a `StatusSelect` dropdown component using Radix UI Select for choosing a status. Develop a `BulkActions` toolbar component using Radix UI Toolbar to house actions for selected properties.",
            "status": "done",
            "testStrategy": "Visually verify the StatusBadge component displays the correct color for each status. Test the StatusSelect dropdown renders all status options. Use Storybook or a similar tool to test components in isolation.",
            "parentId": "undefined",
            "updatedAt": "2025-10-07T19:55:40.028Z"
          },
          {
            "id": 4,
            "title": "Integrate Status Management into Properties Table",
            "description": "Enhance the properties table with status selection, bulk actions, and user feedback mechanisms like loading states and notifications.",
            "dependencies": [
              "39.2",
              "39.3"
            ],
            "details": "Modify the `PropertiesTable` to include a checkbox for each row to enable bulk selection. Integrate the `BulkActions` toolbar, which appears when properties are selected. Add the `StatusSelect` dropdown or a 'Mark as Sold' button to each row for individual updates. Implement loading states for API calls and use Sonner for toast notifications on success or error.",
            "status": "done",
            "testStrategy": "Confirm that selecting properties via checkboxes reveals the BulkActions toolbar. Test bulk update functionality from the UI. Test individual status updates. Verify that loading states are shown during API calls and that success/error toast notifications appear correctly.",
            "parentId": "undefined",
            "updatedAt": "2025-10-07T20:05:47.557Z"
          },
          {
            "id": 5,
            "title": "Filter Exports Based on Property Status",
            "description": "Exclude sold properties from ministry-facing XML and CSV data exports to ensure compliance and data accuracy.",
            "dependencies": [
              "39.1"
            ],
            "details": "Modify the logic for generating the Ministry XML and any related CSV exports. Update the database queries or data filtering process to exclude properties with a 'sold' status. Ensure that only properties marked as 'available' or 'reserved' are included in the final export files.",
            "status": "done",
            "testStrategy": "Generate the Ministry XML and CSV exports after marking several properties as 'sold'. Verify that the sold properties are correctly excluded from the generated files. Confirm that 'available' and 'reserved' properties are still included.",
            "parentId": "undefined",
            "updatedAt": "2025-10-07T20:08:11.361Z"
          }
        ],
        "updatedAt": "2025-10-07T20:08:11.361Z"
      },
      {
        "id": "40",
        "title": "Enhance Settings Page with Complete User Management",
        "description": "Expand the existing settings page to include profile management, API configuration, notification preferences, and account actions",
        "details": "Enhance src/app/dashboard/settings/page.tsx with four sections: 1) Profile Settings - company name, NIP, REGON, email, phone with form validation, 2) API Configuration - display client_id (read-only), regenerate client_id button with confirmation dialog, ministry endpoint URLs with copy buttons, 3) Notification Preferences - email notifications toggle, frequency selection (daily/weekly), 4) Account Actions - change password, delete account with confirmation. Create API endpoints: GET /api/user/profile, PATCH /api/user/profile, POST /api/user/regenerate-client-id. Use Radix UI components for forms, dialogs, and switches. Implement form validation with Zod schemas.",
        "testStrategy": "Test form validation for required fields and formats, verify profile updates persist in database, test client_id regeneration creates new UUID, confirm success/error toast notifications display correctly, validate all API endpoints work properly",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create API Endpoints for User Profile Management",
            "description": "Implement the backend API routes required to fetch and update user profile information, which will serve as the data layer for the settings page.",
            "dependencies": [],
            "details": "Create the API route `GET /api/user/profile` to retrieve the current user's data, including company name, NIP, REGON, email, phone, and client_id. Create the API route `PATCH /api/user/profile` to update the user's profile information, ensuring server-side validation of the incoming data.",
            "status": "pending",
            "testStrategy": "Verify that GET /api/user/profile returns the correct user data. Test PATCH /api/user/profile with valid and invalid data to ensure updates are successful and validation errors are returned correctly.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Profile Settings Form UI",
            "description": "Build the 'Profile Settings' section on the settings page, allowing users to view and edit their profile information with client-side validation.",
            "dependencies": [
              "40.1"
            ],
            "details": "In `src/app/dashboard/settings/page.tsx`, create a form using Radix UI components for company name, NIP, REGON, email, and phone. Implement client-side validation using a Zod schema. Connect the form to the GET and PATCH API endpoints to fetch initial data and submit updates. Implement loading and disabled states during form submission.",
            "status": "pending",
            "testStrategy": "Test form validation for all fields (required, format). Verify that submitting the form successfully calls the PATCH API and updates the UI. Confirm that data from the GET API correctly populates the form on initial load.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Develop API Configuration Section with Client ID Regeneration",
            "description": "Create the 'API Configuration' section, including the backend logic and UI for displaying API details and regenerating the client ID.",
            "dependencies": [
              "40.1"
            ],
            "details": "Implement the `POST /api/user/regenerate-client-id` endpoint to generate a new UUID for the user's client_id. In the UI, display the read-only client_id fetched from the profile API. Add a 'Regenerate' button that triggers a Radix UI confirmation dialog before calling the API. Display the static ministry endpoint URLs with 'Copy to Clipboard' buttons.",
            "status": "pending",
            "testStrategy": "Verify the client_id is displayed correctly. Test the 'Regenerate' button, confirm the dialog appears, and a new UUID is generated and persisted upon confirmation. Test the 'Copy' buttons to ensure they copy the correct URLs to the clipboard.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Build UI for Notification Preferences and Account Actions",
            "description": "Construct the user interface for the 'Notification Preferences' and 'Account Actions' sections using Radix UI components for user interaction.",
            "dependencies": [],
            "details": "In the 'Notification Preferences' section, add a Radix UI Switch for enabling/disabling email notifications and a Radix UI Select for choosing frequency (daily/weekly). In the 'Account Actions' section, add buttons for 'Change Password' and 'Delete Account', with each button configured to trigger a respective Radix UI confirmation dialog. This subtask focuses on UI structure and component implementation.",
            "status": "pending",
            "testStrategy": "Confirm all UI components (Switch, Select, Buttons, Dialogs) render correctly. Verify that interacting with the components (e.g., opening a dialog) works as expected.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Implement Backend for Account Actions and Final Integration",
            "description": "Create the necessary API endpoints for account actions and notification preferences, and integrate all four sections into a cohesive settings page with user feedback.",
            "dependencies": [
              "40.2",
              "40.3",
              "40.4"
            ],
            "details": "Create API endpoints to handle changing passwords and deleting user accounts. Implement the backend logic to update notification preferences in the database. Connect the UI components from subtask 4 to these new endpoints. Implement success and error toast notifications for all actions on the page (profile update, ID regeneration, password change, etc.) to provide clear user feedback.",
            "status": "pending",
            "testStrategy": "Test the API endpoints for changing password, deleting account, and updating notification preferences. Verify that the UI correctly calls these endpoints. Confirm that success/error toast notifications are displayed appropriately for every user action on the settings page.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2025-10-07T18:00:23.861Z"
      },
      {
        "id": "41",
        "title": "Create Notifications System and Page",
        "description": "Implement a comprehensive notifications system with database table, API endpoints, and /notifications page UI",
        "details": "Create notifications table in Supabase with columns: id, developer_id, type (upload_complete, upload_error, ministry_sync, system_announcement), title, message, read (boolean), created_at. Implement RLS policies for developer-only access. Create API endpoints: GET /api/notifications (list with pagination), PATCH /api/notifications/[id] (mark as read), DELETE /api/notifications/[id] (delete). Build /notifications page showing list sorted by newest first, with mark as read/unread buttons, delete functionality, and empty state. Add unread count badge in header that updates real-time. Use existing Radix UI components for consistent styling.",
        "testStrategy": "Test notifications page renders correctly, verify mark as read/unread functionality, confirm delete operations work, test unread count badge updates correctly, validate RLS policies prevent unauthorized access, test empty state display",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Implement Notifications Table with RLS Policies in Supabase",
            "description": "Create the notifications table in Supabase with all required columns and implement Row Level Security (RLS) policies to ensure only the owning developer can access their notifications.",
            "dependencies": [],
            "details": "Define the table with columns: id, developer_id, type (enum: upload_complete, upload_error, ministry_sync, system_announcement), title, message, read (boolean), created_at. Add appropriate indexes for efficient querying. Write RLS policies restricting access to notifications where developer_id matches the authenticated user.",
            "status": "done",
            "testStrategy": "Verify table schema matches requirements, test RLS by attempting to access notifications as different users, and confirm unauthorized access is blocked.",
            "updatedAt": "2025-10-08T07:31:56.341Z",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Develop API Endpoints for Notifications CRUD Operations",
            "description": "Implement REST API endpoints for listing, updating, and deleting notifications, supporting pagination and developer-only access.",
            "dependencies": [
              1
            ],
            "details": "Create GET /api/notifications (with pagination), PATCH /api/notifications/[id] (mark as read/unread), and DELETE /api/notifications/[id] (delete notification). Ensure endpoints enforce authentication and RLS, and return appropriate error messages for unauthorized access.",
            "status": "done",
            "testStrategy": "Write integration tests for each endpoint, including pagination, marking as read/unread, and deletion. Test that endpoints reject unauthorized requests.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T07:32:50.316Z"
          },
          {
            "id": 3,
            "title": "Implement Real-Time Unread Count Badge in Header",
            "description": "Add a real-time unread notifications count badge to the application header, updating automatically as notifications are read or received.",
            "dependencies": [
              2
            ],
            "details": "Use Supabase real-time subscriptions to listen for changes in the notifications table for the current developer. Update the unread count badge in the header UI using existing Radix UI components for styling consistency.",
            "status": "done",
            "testStrategy": "Simulate notification creation and status changes, verify badge updates in real-time, and test UI responsiveness.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T07:34:34.909Z"
          },
          {
            "id": 4,
            "title": "Build /notifications Page UI with List, Actions, and Empty State",
            "description": "Create the /notifications page displaying notifications sorted by newest first, with mark as read/unread and delete actions, and an empty state when there are no notifications.",
            "dependencies": [
              2
            ],
            "details": "Fetch notifications from the API, display them in a list using Radix UI components, and implement buttons for marking as read/unread and deleting. Show a styled empty state when the list is empty. Ensure accessibility and responsive design.",
            "status": "done",
            "testStrategy": "Test UI rendering with various notification states, verify actions trigger correct API calls and UI updates, and confirm empty state displays when appropriate.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T07:34:35.850Z"
          },
          {
            "id": 5,
            "title": "End-to-End Testing and Validation of Notifications System",
            "description": "Perform comprehensive end-to-end testing of the notifications system, covering database, API, UI, and real-time features.",
            "dependencies": [
              3,
              4
            ],
            "details": "Test the full workflow: notification creation, listing, marking as read/unread, deletion, real-time updates, RLS enforcement, and UI consistency. Validate error handling and edge cases, such as unauthorized access and empty states.",
            "status": "done",
            "testStrategy": "Use automated and manual tests to verify all acceptance criteria, including security, real-time updates, and user experience across devices.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T07:34:36.771Z"
          }
        ],
        "updatedAt": "2025-10-08T07:34:36.771Z"
      },
      {
        "id": "42",
        "title": "Add Dashboard Statistics Cards",
        "description": "Create overview statistics cards displaying key metrics on the dashboard top section",
        "details": "Create statistics cards component showing: total properties, available properties, sold properties (this month), average price per m². Design 4-card grid layout (2x2 on mobile, 4x1 on desktop) with icons from Lucide React, values, labels, and trend indicators (↑/↓ compared to last month). Create API endpoint GET /api/dashboard/stats returning aggregated statistics from properties table. Position cards above UploadWidget in dashboard layout. Include loading skeleton states and error handling. Use date-fns for date calculations and filtering.",
        "testStrategy": "Verify stats cards render above upload widget, test data refreshes on page load, confirm loading skeleton displays during fetch, validate error states handled gracefully, test responsive layout on mobile and desktop",
        "priority": "low",
        "dependencies": [
          "39"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Statistics API Endpoint",
            "description": "Implement GET /api/dashboard/stats endpoint that aggregates property statistics from the database",
            "dependencies": [],
            "details": "Create route at src/app/api/dashboard/stats/route.ts that queries the properties table to calculate: total properties count, available properties count (status = 'available'), sold properties count for current month (status = 'sold' + date filtering), and average price per m2. Use date-fns for current month filtering with proper timezone handling. Include previous month calculations for trend comparison. Implement proper error handling, authentication via Supabase auth, and RLS policy enforcement. Return JSON response with statistics and trend indicators.",
            "status": "done",
            "testStrategy": "Test endpoint returns correct aggregated data, verify authentication required, confirm RLS policies work, test with empty database, validate date filtering logic",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T07:45:24.347Z"
          },
          {
            "id": 2,
            "title": "Create Statistics Cards Component",
            "description": "Build reusable StatsCard component and StatisticsCards container component for displaying dashboard metrics",
            "dependencies": [],
            "details": "Create components/dashboard/statistics-cards.tsx with individual StatsCard component using existing Card UI components from src/components/ui/card.tsx. Include props for title, value, icon (from lucide-react), trend direction and percentage. Create StatisticsCards container component that fetches data from /api/dashboard/stats endpoint using SWR for caching. Implement responsive grid layout (2x2 on mobile, 4x1 on desktop) using CSS Grid and Tailwind classes. Add loading skeleton states using existing LoadingState pattern and error handling with proper error display.",
            "status": "done",
            "testStrategy": "Test component renders correctly with mock data, verify responsive layout on different screen sizes, confirm loading states display properly, test error handling scenarios",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T07:45:25.294Z"
          },
          {
            "id": 3,
            "title": "Add Icons and Trend Indicators",
            "description": "Implement icon selection and trend indicator logic for each statistics card",
            "dependencies": [
              "42.2"
            ],
            "details": "Add lucide-react icons to StatsCard component: Building2 for total properties, Home for available properties, HandCoins for sold properties, Calculator for average price per m2. Implement trend indicator with up/down arrows (ChevronUp, ChevronDown) and percentage change display. Add conditional styling for positive (green) and negative (red) trends. Ensure icons are accessible with proper aria-labels and maintain consistent sizing across all cards.",
            "status": "done",
            "testStrategy": "Verify correct icons display for each metric, test trend indicators show proper colors and arrows, confirm accessibility attributes are present",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T07:45:26.192Z"
          },
          {
            "id": 4,
            "title": "Integrate Statistics Cards into Dashboard Layout",
            "description": "Add StatisticsCards component to dashboard page above the UploadWidget component",
            "dependencies": [
              "42.2"
            ],
            "details": "Edit src/app/dashboard/page.tsx to import and add StatisticsCards component in the dashboard grid section, positioned before the UploadWidget component. Ensure proper spacing using existing space-y-6 pattern. Add Suspense wrapper with appropriate loading fallback to match existing lazy-loaded components pattern. Maintain existing dashboard structure and styling consistency.",
            "status": "done",
            "testStrategy": "Verify statistics cards appear above upload widget, confirm proper spacing and layout integration, test loading states work correctly with Suspense",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T07:45:27.069Z"
          },
          {
            "id": 5,
            "title": "Add Data Fetching and Error Handling",
            "description": "Implement SWR-based data fetching with proper error handling and loading states",
            "dependencies": [
              "42.1",
              "42.2"
            ],
            "details": "Add SWR hook in StatisticsCards component to fetch data from /api/dashboard/stats with automatic revalidation on page focus. Implement error boundary integration and fallback states for network errors. Add retry logic and loading skeletons that match existing component patterns. Use existing error display components and ensure consistent error messaging. Include data refresh on property updates using SWR mutate functionality.",
            "status": "done",
            "testStrategy": "Test data loads correctly on component mount, verify error states display properly, confirm retry functionality works, test loading skeleton appears during fetch",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T07:45:27.977Z"
          },
          {
            "id": 6,
            "title": "Design Responsive 4-Card Grid Layout for Statistics Cards",
            "description": "Create a responsive grid layout for the dashboard statistics cards, displaying 2x2 on mobile and 4x1 on desktop.",
            "dependencies": [],
            "details": "Implement a grid layout using CSS grid or a UI library (e.g., Tailwind, MUI) to ensure the cards display as 2x2 on mobile and 4x1 on desktop. The layout should be visually consistent with the dashboard's design system.",
            "status": "pending",
            "testStrategy": "Resize the dashboard on different devices and verify the cards rearrange correctly (2x2 on mobile, 4x1 on desktop).",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Implement Statistics Cards Component with Icons and Trend Indicators",
            "description": "Develop a reusable statistics card component displaying an icon, value, label, and trend indicator (↑/↓) using Lucide React icons.",
            "dependencies": [
              6
            ],
            "details": "Create a card component that accepts props for icon, value, label, and trend direction. Use Lucide React for icons and display a trend arrow (up/down) with color coding. Ensure accessibility and consistent styling.",
            "status": "pending",
            "testStrategy": "Render the component with sample data and verify correct display of icon, value, label, and trend indicator.",
            "parentId": "undefined"
          },
          {
            "id": 8,
            "title": "Create API Endpoint GET /api/dashboard/stats for Aggregated Metrics",
            "description": "Develop a backend API endpoint that returns aggregated statistics: total properties, available properties, sold properties (this month), and average price per m².",
            "dependencies": [],
            "details": "Implement GET /api/dashboard/stats to query the properties table, aggregate the required metrics, and return them in a JSON response. Use date-fns for date filtering (e.g., sold properties this month). Handle errors and edge cases.",
            "status": "pending",
            "testStrategy": "Call the endpoint with test data and verify the response structure and accuracy of aggregated values.",
            "parentId": "undefined"
          },
          {
            "id": 9,
            "title": "Integrate Statistics Cards with API Data, Loading Skeletons, and Error Handling",
            "description": "Fetch statistics from the API, display loading skeletons while fetching, and handle error states in the statistics cards.",
            "dependencies": [
              7,
              8
            ],
            "details": "Use React hooks (e.g., useEffect, useState) or a data-fetching library (e.g., SWR, React Query) to fetch data from /api/dashboard/stats. Show skeleton loaders during fetch and display error messages if the request fails.",
            "status": "pending",
            "testStrategy": "Simulate loading and error states; verify skeletons and error messages appear as expected.",
            "parentId": "undefined"
          },
          {
            "id": 10,
            "title": "Position Statistics Cards Above UploadWidget in Dashboard Layout",
            "description": "Update the dashboard layout to place the statistics cards grid above the UploadWidget component.",
            "dependencies": [
              9
            ],
            "details": "Modify the dashboard page/component to render the statistics cards grid at the top, directly above the UploadWidget. Ensure layout consistency and spacing.",
            "status": "pending",
            "testStrategy": "Open the dashboard and confirm the statistics cards appear above the UploadWidget, with correct spacing and order.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2025-10-08T07:45:30.158Z"
      },
      {
        "id": "43",
        "title": "Implement Email Notification System",
        "description": "Set up automated email notifications for important events using Resend API with React Email templates",
        "details": "Create email notification system using existing Resend dependency and @react-email/render. Build email templates: upload completed (with summary), upload failed (with error details), weekly report (every Monday with stats). Implement notification triggers in upload API routes and create weekly cron job using Vercel Cron API routes. Create email templates directory with React Email components ensuring mobile-responsive design. Add opt-out functionality in settings page. Log failed emails for debugging. Use environment variables for Resend API key configuration.",
        "testStrategy": "Test emails send successfully via Resend, verify templates are mobile-responsive, confirm users can opt-out in settings, test weekly report generation and sending, validate failed email logging works correctly",
        "priority": "low",
        "dependencies": [
          "41"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Set Up Resend API Integration and Environment Variables",
            "description": "Integrate the Resend API for sending emails and securely configure API keys using environment variables.",
            "dependencies": [],
            "details": "Install and configure the Resend API client in the backend. Store the API key in environment variables and ensure it is accessed securely in code. Validate the connection by sending a test email.",
            "status": "done",
            "testStrategy": "Send a test email using the Resend API and verify receipt. Confirm API key is not exposed in code or logs.",
            "updatedAt": "2025-10-08T07:40:27.818Z",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Develop Mobile-Responsive React Email Templates",
            "description": "Create reusable, mobile-friendly email templates for upload completed, upload failed, and weekly report notifications using @react-email/render.",
            "dependencies": [
              1
            ],
            "details": "Set up a directory for React Email components. Implement three templates: upload completed (with summary), upload failed (with error details), and weekly report (with stats). Ensure all templates are mobile-responsive and visually consistent.",
            "status": "done",
            "testStrategy": "Render templates in development, send test emails, and verify correct appearance on desktop and mobile email clients.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T07:40:28.733Z"
          },
          {
            "id": 3,
            "title": "Implement Notification Triggers in API and Weekly Cron Job",
            "description": "Add logic to trigger email notifications in upload API routes and schedule weekly report emails using Vercel Cron API routes.",
            "dependencies": [
              1,
              2
            ],
            "details": "Modify upload API routes to trigger the appropriate email template on success or failure. Set up a Vercel Cron job to send weekly reports every Monday. Ensure correct data is passed to templates.",
            "status": "done",
            "testStrategy": "Trigger uploads and failures to verify emails are sent. Confirm weekly report is sent on schedule with accurate stats.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T07:40:29.627Z"
          },
          {
            "id": 4,
            "title": "Add Opt-Out Functionality to User Settings",
            "description": "Enable users to opt out of email notifications via a settings page toggle.",
            "dependencies": [
              1
            ],
            "details": "Update the settings page UI to include an opt-out toggle. Store user preferences in the database and ensure notification triggers respect this setting before sending emails.",
            "status": "done",
            "testStrategy": "Toggle opt-out in settings, perform actions that would trigger emails, and verify that opted-out users do not receive notifications.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T07:40:30.519Z"
          },
          {
            "id": 5,
            "title": "Log Failed Email Attempts for Debugging",
            "description": "Implement logging for failed email sends to aid in debugging and monitoring.",
            "dependencies": [
              1,
              3
            ],
            "details": "Capture errors from the Resend API when sending emails. Log relevant details (timestamp, user, error message) to a persistent store or monitoring service for later review.",
            "status": "done",
            "testStrategy": "Simulate email send failures and verify that error logs are created with sufficient detail for troubleshooting.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T07:40:31.403Z"
          }
        ],
        "updatedAt": "2025-10-08T07:40:31.403Z"
      },
      {
        "id": "44",
        "title": "Database Schema Updates for New Features",
        "description": "Create and run database migrations for property status, notifications table, and email preferences",
        "details": "Create Supabase migrations for: 1) Add status column to properties table with enum type (available, sold, reserved) and default 'available', 2) Create notifications table with proper indexes and RLS policies, 3) Add email_notifications_enabled and notification_frequency columns to developers table. Create proper indexes for performance: properties.status, notifications.developer_id+read+created_at. Implement RLS policies ensuring developers can only access their own data. Update TypeScript types to reflect schema changes. Test migrations in development before applying to production.",
        "testStrategy": "Test migrations apply successfully without data loss, verify RLS policies work correctly, confirm indexes improve query performance, validate TypeScript types match database schema, test rollback procedures if needed",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-10-07T18:08:15.050Z"
      },
      {
        "id": "45",
        "title": "Integration Testing and Quality Assurance",
        "description": "Comprehensive testing of all new features and existing functionality to ensure production readiness",
        "details": "Create comprehensive test suite covering: unit tests for property status management, notifications API, statistics calculations; integration tests for email system, settings updates, dashboard functionality; end-to-end tests for critical user flows (upload → mark as sold → verify ministry endpoints). Test ministry compliance endpoints with various property statuses. Verify TypeScript compilation with 'npm run build'. Test responsive design on mobile/tablet/desktop. Perform security audit of RLS policies and API endpoints. Load test ministry endpoints. Create deployment checklist and verify Vercel deployment succeeds.",
        "testStrategy": "All tests pass including unit, integration, and e2e tests. TypeScript compilation succeeds. Ministry endpoints return correct data excluding sold properties. Security audit passes. Load testing shows acceptable performance. Vercel deployment completes successfully.",
        "priority": "high",
        "dependencies": [
          "36",
          "37",
          "38",
          "39",
          "40",
          "41",
          "42",
          "43",
          "44"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2025-10-08T08:17:08.813Z"
      },
      {
        "id": "46",
        "title": "Update Landing Page with New Pricing Plans and Features",
        "description": "Update the main landing page to reflect the new subscription plans (Basic 149zł, Pro 249zł, Enterprise 399zł) with corrected features including subdomain support, custom domains, and a pricing calculator for Pro plan.",
        "details": "This task involves comprehensive updates to the landing page (src/app/page.tsx) and pricing section (src/components/PricingSection.tsx) to align with the new subscription model:\n\n**Pricing Plan Updates:**\n- Basic: 149zł/month, 1 investment, max 20 properties\n- Pro: 249zł/month, 2 investments + 50zł per additional, unlimited properties, includes subdomains\n- Enterprise: 399zł/month, unlimited everything, includes custom domains\n\n**Feature Updates Required:**\n1. Update PricingSection.tsx with correct pricing (Basic 149zł, Pro 249zł, Enterprise 399zł)\n2. Correct plan features - Basic (1 investment, 20 properties), Pro (2+ investments, unlimited properties, subdomains), Enterprise (unlimited everything, custom domains)\n3. Add pricing calculator component for Pro plan showing additional investment costs (50zł each)\n4. Update landing page hero section to mention new pricing structure\n5. Update FAQ section with current pricing information\n6. Add price history features mention in plan descriptions\n7. Ensure all pricing references throughout the page are consistent\n\n**Implementation Details:**\n- Modify plans array in PricingSection.tsx with correct monthly/annual pricing\n- Update feature lists to accurately reflect plan capabilities\n- Create new PricingCalculator component for Pro plan additional investment cost calculation\n- Update landing page text to reference correct pricing tiers\n- Ensure responsive design maintains quality across all devices\n- Update structured data/metadata if pricing is referenced\n\n**Technical Considerations:**\n- Use existing Radix UI components for consistency\n- Maintain current responsive design patterns\n- Ensure pricing calculator follows existing design system\n- Update TypeScript interfaces if new pricing structure requires it\n- Test across different viewport sizes",
        "testStrategy": "Verify pricing displays correctly across all screen sizes, test pricing calculator functionality (Pro plan additional investment calculations), confirm all plan features are accurately represented, validate FAQ section contains updated pricing, ensure structured data reflects correct pricing, test annual/monthly toggle works with new prices, verify CTA buttons link to correct signup flows with pricing parameters, test responsive design on mobile/tablet/desktop, confirm no old pricing information remains on the page, validate landing page loads quickly with new content.",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Update PricingSection.tsx with New Pricing Plans",
            "description": "Modify the PricingSection.tsx component to reflect the updated subscription plans and pricing tiers.",
            "dependencies": [],
            "details": "Edit the plans array in src/components/PricingSection.tsx to set Basic at 149zł/month, Pro at 249zł/month (plus 50zł per additional investment), and Enterprise at 399zł/month. Ensure monthly and annual pricing options are accurate and update any related metadata.",
            "status": "done",
            "testStrategy": "Verify that the pricing values display correctly for each plan across all screen sizes and check that structured data/metadata matches the new pricing.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T13:16:14.869Z"
          },
          {
            "id": 2,
            "title": "Correct Feature Lists for All Plans",
            "description": "Update the feature descriptions for Basic, Pro, and Enterprise plans to match the new specifications.",
            "dependencies": [
              1
            ],
            "details": "Adjust the feature lists in PricingSection.tsx so Basic shows 1 investment and 20 properties, Pro shows 2 investments plus unlimited properties and subdomain support, and Enterprise shows unlimited investments/properties and custom domain support. Ensure all feature bullets are clear and accurate.",
            "status": "done",
            "testStrategy": "Check that each plan displays the correct features and that the feature lists are consistent with the new requirements.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T13:16:15.792Z"
          },
          {
            "id": 3,
            "title": "Create Pricing Calculator Component for Pro Plan",
            "description": "Develop a new component to calculate additional investment costs for the Pro plan.",
            "dependencies": [
              1,
              2
            ],
            "details": "Implement a PricingCalculator component in src/components that allows users to input the number of additional investments for the Pro plan and dynamically displays the total monthly cost (base 249zł + 50zł per extra investment). Integrate with existing design system and Radix UI components.",
            "status": "done",
            "testStrategy": "Test the calculator for correct cost computation, UI responsiveness, and integration with the PricingSection. Validate with multiple input scenarios.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T13:16:16.713Z"
          },
          {
            "id": 4,
            "title": "Update Landing Page Hero Section Text",
            "description": "Revise the hero section of the landing page to mention the new pricing structure and plan highlights.",
            "dependencies": [
              1,
              2
            ],
            "details": "Edit src/app/page.tsx to update the hero section headline and supporting text, referencing the new pricing tiers and key features. Ensure messaging is clear and matches the updated plans.",
            "status": "done",
            "testStrategy": "Review the hero section on desktop and mobile to confirm the new pricing is prominently and accurately displayed.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T13:16:17.642Z"
          },
          {
            "id": 5,
            "title": "Update FAQ Section with Current Pricing Information",
            "description": "Revise the FAQ section to include accurate details about the new pricing plans and features.",
            "dependencies": [
              1,
              2
            ],
            "details": "Update the FAQ entries in src/app/page.tsx or relevant FAQ component to reflect the new pricing, plan limits, and calculator functionality. Ensure answers are clear and up-to-date.",
            "status": "done",
            "testStrategy": "Check that all FAQ answers reference the correct pricing and features, and that no outdated information remains.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T13:16:18.568Z"
          },
          {
            "id": 6,
            "title": "Add Price History Feature Mention in Plan Descriptions",
            "description": "Include references to price history features in the plan descriptions where applicable.",
            "dependencies": [
              2
            ],
            "details": "Edit the plan descriptions in PricingSection.tsx and any relevant landing page sections to mention price history features for applicable plans. Ensure the wording is consistent and highlights the feature appropriately.",
            "status": "done",
            "testStrategy": "Verify that price history features are mentioned in the correct plans and that the descriptions are clear and visible.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T13:16:19.518Z"
          },
          {
            "id": 7,
            "title": "Perform Consistency Checks and Responsive Design Validation",
            "description": "Ensure all pricing references are consistent across the landing page and validate responsive design.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5,
              6
            ],
            "details": "Review the entire landing page to confirm all pricing and feature references are updated and consistent. Test the page across multiple devices and viewport sizes to ensure the design remains responsive and visually correct.",
            "status": "done",
            "testStrategy": "Perform manual and automated UI tests for consistency and responsiveness. Use browser tools to check layout and pricing display on various devices.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T13:16:20.466Z"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 7,
        "expansionPrompt": "Break down the landing page update into: (1) PricingSection.tsx updates, (2) feature list corrections, (3) pricing calculator component creation, (4) hero section text update, (5) FAQ section update, (6) price history feature mention, (7) consistency checks and responsive design validation.",
        "updatedAt": "2025-10-08T13:16:20.466Z"
      },
      {
        "id": "47",
        "title": "Update Subscription Plans Configuration in Code",
        "description": "Update src/lib/subscription-plans.ts to match new PRD pricing: Basic (14900 grosze, 20 properties, 1 project), Pro (unlimited properties, 2 projects, 5000 grosze additional project fee), Enterprise (unlimited everything).",
        "details": "Update the SUBSCRIPTION_PLANS configuration object in src/lib/subscription-plans.ts to match the new PRD specifications:\n\n1. **Basic Plan Updates**: Already correctly configured at 14900 grosze (149zł), 20 properties limit, 1 project limit\n\n2. **Pro Plan Updates**: Change price from 24900 to match PRD (verify exact amount), ensure propertiesLimit is null (unlimited), projectsLimit is 2, additionalProjectFee is 5000 grosze (50zł)\n\n3. **Enterprise Plan Updates**: Ensure propertiesLimit and projectsLimit are both null (unlimited)\n\n4. **Update Features Arrays**: Review and update the features arrays for each plan to accurately reflect current capabilities and remove any outdated features\n\n5. **Add calculateProPlanCost Function**: Implement a dedicated function specifically for calculating Pro plan costs including base price plus additional project fees, making it easier for UI components to display dynamic pricing\n\n6. **Verify Existing Functions**: Review calculateMonthlyCost, calculateBilling, and other utility functions to ensure they work correctly with the updated plan configuration\n\n7. **Update Comments**: Ensure the header comment block reflects the correct pricing (149zł, 249zł, 399zł)\n\n8. **Test Integration**: Verify that existing components using this configuration (PricingSection, dashboard components) will work correctly with the updates",
        "testStrategy": "Verify all plan prices match PRD specifications (Basic: 149zł, Pro: 249zł with 50zł additional projects, Enterprise: 399zł). Test calculateProPlanCost function returns correct totals for various additional project counts. Confirm existing calculateMonthlyCost and calculateBilling functions work with updated configuration. Check that features arrays are accurate and complete. Validate TypeScript compilation passes. Test that pricing components render correctly with new configuration.",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Verify Basic Plan Configuration",
            "description": "Check that the Basic plan in src/lib/subscription-plans.ts matches the PRD: 14900 grosze, 20 properties, 1 project.",
            "dependencies": [],
            "details": "Review the SUBSCRIPTION_PLANS object for the Basic plan. Confirm price, propertiesLimit, and projectsLimit are set to 14900, 20, and 1 respectively. No changes expected if already correct.",
            "status": "done",
            "testStrategy": "Write a unit test to assert Basic plan fields match PRD values.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T13:24:52.883Z"
          },
          {
            "id": 2,
            "title": "Update Pro Plan Configuration",
            "description": "Update the Pro plan to match PRD: correct price, unlimited properties, 2 projects, 5000 grosze additional project fee.",
            "dependencies": [
              1
            ],
            "details": "Set Pro plan price to PRD value (verify if 24900 grosze), propertiesLimit to null, projectsLimit to 2, and additionalProjectFee to 5000. Double-check all fields for accuracy.",
            "status": "done",
            "testStrategy": "Unit test to verify Pro plan fields and additionalProjectFee logic.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T13:24:53.789Z"
          },
          {
            "id": 3,
            "title": "Verify Enterprise Plan Configuration",
            "description": "Ensure Enterprise plan has unlimited properties and projects (both limits set to null).",
            "dependencies": [
              2
            ],
            "details": "Check that propertiesLimit and projectsLimit for Enterprise are null. Confirm other fields align with PRD.",
            "status": "done",
            "testStrategy": "Unit test to assert Enterprise plan limits are null.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T13:24:54.694Z"
          },
          {
            "id": 4,
            "title": "Update Features Arrays for All Plans",
            "description": "Review and update the features arrays for each plan to reflect current capabilities and remove outdated features.",
            "dependencies": [
              3
            ],
            "details": "Compare features arrays in the configuration with PRD and product documentation. Add, remove, or update features as needed for Basic, Pro, and Enterprise.",
            "status": "done",
            "testStrategy": "Unit test to check features arrays match expected values for each plan.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T13:24:55.603Z"
          },
          {
            "id": 5,
            "title": "Implement calculateProPlanCost Function",
            "description": "Add a function to calculate Pro plan cost, including base price and additional project fees.",
            "dependencies": [
              4
            ],
            "details": "Create calculateProPlanCost in src/lib/subscription-plans.ts. The function should accept the number of projects and return the correct total cost based on base price and additionalProjectFee.",
            "status": "done",
            "testStrategy": "Unit tests for calculateProPlanCost with various project counts.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T13:24:56.505Z"
          },
          {
            "id": 6,
            "title": "Integration and Regression Testing",
            "description": "Test all dependent components and utilities to ensure correct integration with the updated subscription plans configuration.",
            "dependencies": [
              5
            ],
            "details": "Run and expand integration tests for PricingSection, dashboard, and billing utilities. Verify that all plan logic, pricing calculations, and UI displays are correct and no regressions are introduced.",
            "status": "done",
            "testStrategy": "Automated integration and regression tests covering all affected components and functions.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T13:24:57.405Z"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Decompose the configuration update into: (1) Basic plan verification, (2) Pro plan updates (price, limits, additional fee), (3) Enterprise plan verification, (4) features array updates, (5) calculateProPlanCost function implementation, (6) integration and regression testing.",
        "updatedAt": "2025-10-08T13:24:57.405Z"
      },
      {
        "id": "48",
        "title": "Enforce Subscription Limits in Upload & Properties APIs",
        "description": "Create middleware enforcePropertyLimit() and enforceProjectLimit() to check subscription limits before allowing uploads and property creation.",
        "details": "Create middleware functions that check subscription limits before allowing uploads and property creation:\n\n1. **Create src/lib/subscription-limits-middleware.ts**:\n   - enforcePropertyLimit(developerId: string, newPropertiesCount: number): checks if adding properties would exceed plan limits\n   - enforceProjectLimit(developerId: string): checks if creating projects would exceed plan limits\n   - Use existing canAddProperty() and canAddProject() functions from subscription-plans.ts\n   - Return helpful error messages with current usage and upgrade links\n\n2. **Update POST /api/upload route** (src/app/api/upload/route.ts:281):\n   - Add property limit check before savePropertiesToDatabase()\n   - Check total properties count that would result after upload\n   - Return 403 with usage details and upgrade link if limit exceeded\n\n3. **Update POST /api/properties route** (create new endpoint):\n   - Add property limit check before creating individual properties\n   - Use enforcePropertyLimit() middleware\n   - Return 403 with helpful error message if limit exceeded\n\n4. **Error Response Format**:\n   ```json\n   {\n     \"error\": \"Property limit exceeded\",\n     \"currentUsage\": { \"properties\": 18, \"limit\": 20 },\n     \"message\": \"You have reached your plan limit of 20 properties. Upgrade to Pro for unlimited properties.\",\n     \"upgradeUrl\": \"/dashboard/settings#subscription\"\n   }\n   ```\n\n5. **Integration Points**:\n   - Use existing checkSubscriptionLimits() from subscription-plans.ts:300\n   - Integrate with existing rate limiting in upload route\n   - Maintain backward compatibility with existing upload flow",
        "testStrategy": "Test property limit enforcement: 1) Create developer with Basic plan (20 property limit), 2) Upload CSV with 21 properties and verify 403 response with helpful message, 3) Upload 19 properties successfully, then try to upload 2 more and verify rejection, 4) Upgrade to Pro plan and verify unlimited properties work, 5) Test project limit enforcement similarly. Verify error messages include current usage, plan limits, and upgrade links. Test that existing functionality continues to work for users within limits.",
        "status": "done",
        "dependencies": [
          "47"
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Property and Project Limit Middleware",
            "description": "Develop enforcePropertyLimit() and enforceProjectLimit() middleware functions to check subscription limits before allowing uploads and property creation.",
            "dependencies": [],
            "details": "Create src/lib/subscription-limits-middleware.ts. Implement enforcePropertyLimit(developerId, newPropertiesCount) and enforceProjectLimit(developerId) using canAddProperty() and canAddProject() from subscription-plans.ts. Ensure middleware returns detailed error messages with current usage and upgrade links.",
            "status": "done",
            "testStrategy": "Unit test middleware with various developer plans and property/project counts. Verify correct error and success responses for edge cases.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T14:18:09.412Z"
          },
          {
            "id": 2,
            "title": "Integrate Property Limit Middleware with Upload API",
            "description": "Update POST /api/upload route to enforce property limits before saving uploaded properties to the database.",
            "dependencies": [
              1
            ],
            "details": "Modify src/app/api/upload/route.ts to call enforcePropertyLimit() before savePropertiesToDatabase(). Calculate total properties after upload and return 403 with usage details and upgrade link if limit exceeded. Integrate with existing rate limiting logic.",
            "status": "done",
            "testStrategy": "API test: Upload CSVs with property counts at, below, and above plan limits. Confirm correct enforcement and error messaging.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T14:18:10.343Z"
          },
          {
            "id": 3,
            "title": "Integrate Property Limit Middleware with Properties API",
            "description": "Add property limit enforcement to the POST /api/properties endpoint for individual property creation.",
            "dependencies": [
              1
            ],
            "details": "Create or update the POST /api/properties route to use enforcePropertyLimit() middleware before property creation. Return 403 with helpful error message if limit exceeded.",
            "status": "done",
            "testStrategy": "API test: Attempt to create properties individually when at, below, and above plan limits. Validate error responses and successful creation.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T14:18:11.277Z"
          },
          {
            "id": 4,
            "title": "Standardize Error Response Formatting for Limit Enforcement",
            "description": "Define and implement a consistent error response format for subscription limit violations across all affected endpoints.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Ensure all limit enforcement errors use the specified JSON format, including error, currentUsage, message, and upgradeUrl fields. Refactor endpoints to use this format for all relevant error cases.",
            "status": "done",
            "testStrategy": "Unit and integration tests: Trigger limit violations and verify error responses match the required format in all APIs.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T14:18:12.197Z"
          },
          {
            "id": 5,
            "title": "End-to-End Testing of Subscription Limit Enforcement",
            "description": "Perform comprehensive end-to-end tests for all subscription plans and edge cases to ensure correct enforcement and error handling.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Test scenarios: Basic plan (20 property limit), Pro plan (unlimited properties, 2 projects), Enterprise (unlimited). Validate middleware, API integration, error responses, and backward compatibility. Cover upgrades and downgrades.",
            "status": "done",
            "testStrategy": "Automated E2E tests: Simulate uploads and property creation for all plan types, verify enforcement, error messaging, and compatibility with existing flows.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T14:18:13.102Z"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Split the enforcement into: (1) middleware implementation for property/project limits, (2) integration with upload API, (3) integration with properties API, (4) error response formatting, (5) end-to-end testing for all plan scenarios.",
        "updatedAt": "2025-10-08T14:18:13.102Z"
      },
      {
        "id": "49",
        "title": "Implement 14-Day Trial System",
        "description": "Add trial management system with database columns, middleware enforcement, trial-expired page, and dashboard countdown banner.",
        "details": "Implement comprehensive 14-day trial system for new developers:\n\n**1. Database Schema Updates (add to existing migration)**:\n- Add `trial_status` enum column to developers table: ('active', 'expired', 'converted', 'cancelled')\n- Ensure `trial_ends_at` timestamp column exists (already in database schema)\n- Update RLS policies to include trial status checks\n- Set default trial_status='active' and trial_ends_at=NOW() + INTERVAL '14 days' for new registrations\n\n**2. Create Trial Status Middleware**:\n- Create `src/lib/trial-middleware.ts` with `checkTrialStatus(developerId: string)` function\n- Check if trial_ends_at < NOW() and trial_status='active', then update to 'expired'\n- Return trial status and days remaining for UI display\n- Integrate with existing subscription-enforcement.ts to block expired trials\n\n**3. Create Trial Expired Page**:\n- Create `src/app/trial-expired/page.tsx` with upgrade CTA\n- Include pricing cards from PricingSection component\n- Add \"Your 14-day trial has expired\" messaging\n- Integrate with Stripe checkout for plan selection\n- Use existing subscription-plans.ts configuration\n\n**4. Dashboard Trial Banner**:\n- Create `src/components/dashboard/trial-banner.tsx` component\n- Show countdown: \"X days left in your trial\"\n- Display only when subscription_status='trialing' and trial not expired\n- Position above StatisticsCards in dashboard layout\n- Include \"Upgrade Now\" button linking to pricing\n\n**5. Integration Points**:\n- Update signup flow to set trial_ends_at automatically\n- Modify middleware.ts to redirect expired trials to /trial-expired\n- Update upload and properties APIs to check trial status using existing subscription enforcement\n- Ensure ministry endpoints remain accessible during trial period\n\n**Technical Requirements**:\n- Use existing Supabase admin client patterns from lib/supabase/server.ts\n- Follow existing TypeScript patterns and database types\n- Integrate with existing subscription-plans.ts and subscription-enforcement.ts\n- Use existing UI components (Button, Card, Alert) for consistency",
        "testStrategy": "Test trial system functionality: 1) Create new developer account and verify trial_ends_at is set to 14 days from now, 2) Manually update trial_ends_at to past date and verify /trial-expired redirect works, 3) Test trial banner shows correct days remaining for active trials, 4) Verify trial banner hidden for paid subscriptions, 5) Test upload functionality blocked for expired trials with helpful error message, 6) Confirm ministry endpoints remain accessible during active trial, 7) Test upgrade flow from trial-expired page to Stripe checkout, 8) Verify trial_status updates correctly when subscription becomes active",
        "status": "done",
        "dependencies": [
          "47"
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Update Database Schema and RLS Policies for Trial Management",
            "description": "Add trial_status enum column to developers table, ensure trial_ends_at exists, and update Row Level Security (RLS) policies to enforce trial logic.",
            "dependencies": [],
            "details": "Modify the existing migration to add a trial_status column with values ('active', 'expired', 'converted', 'cancelled'). Ensure trial_ends_at timestamp is present. Update RLS policies to restrict access based on trial status. Set defaults for new registrations: trial_status='active', trial_ends_at=NOW() + INTERVAL '14 days'.",
            "status": "done",
            "testStrategy": "Run migration, verify columns and defaults, and test RLS policy enforcement for trial states.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T14:45:12.666Z"
          },
          {
            "id": 2,
            "title": "Implement Trial Status Middleware for Enforcement and UI",
            "description": "Create middleware to check trial status, update expired trials, and provide trial info for UI and enforcement.",
            "dependencies": [
              1
            ],
            "details": "Develop src/lib/trial-middleware.ts with checkTrialStatus(developerId: string). On each request, check if trial_ends_at < NOW() and trial_status='active', then update to 'expired'. Return trial status and days remaining for UI. Integrate with subscription-enforcement.ts to block expired trials.",
            "status": "done",
            "testStrategy": "Unit test middleware logic for all trial states; simulate requests with various trial_ends_at values and verify correct status updates and enforcement.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T14:45:13.620Z"
          },
          {
            "id": 3,
            "title": "Create Trial Expired Page with Upgrade Flow",
            "description": "Develop a dedicated page for expired trials, including upgrade CTA, pricing, and Stripe checkout integration.",
            "dependencies": [
              2
            ],
            "details": "Build src/app/trial-expired/page.tsx with messaging ('Your 14-day trial has expired'), PricingSection cards, and Stripe checkout integration using subscription-plans.ts. Ensure upgrade flow is seamless and UI matches existing components.",
            "status": "done",
            "testStrategy": "End-to-end test: expire a trial, verify redirect to page, test upgrade CTA and Stripe checkout, confirm subscription status updates.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T14:45:14.556Z"
          },
          {
            "id": 4,
            "title": "Develop Dashboard Trial Countdown Banner Component",
            "description": "Add a banner to the dashboard showing days left in trial and upgrade option, visible only for active trials.",
            "dependencies": [
              2
            ],
            "details": "Create src/components/dashboard/trial-banner.tsx to display countdown ('X days left in your trial') above StatisticsCards. Show only when subscription_status='trialing' and trial not expired. Include 'Upgrade Now' button linking to pricing.",
            "status": "done",
            "testStrategy": "UI test: create trial account, verify banner visibility and countdown accuracy, test upgrade button navigation.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T14:45:15.477Z"
          },
          {
            "id": 5,
            "title": "Integrate Trial Logic into Signup Flow",
            "description": "Ensure trial columns are set on registration and expired trials are redirected appropriately.",
            "dependencies": [
              1,
              2
            ],
            "details": "Update signup flow to set trial_ends_at and trial_status for new developers. Modify middleware.ts to redirect expired trials to /trial-expired. Ensure ministry endpoints remain accessible during trial.",
            "status": "done",
            "testStrategy": "Functional test: register new developer, verify trial columns, simulate expiration, confirm redirect and endpoint access.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T14:45:16.388Z"
          },
          {
            "id": 6,
            "title": "Enforce Trial Status in APIs and Middleware",
            "description": "Update upload and properties APIs to check trial status and enforce restrictions using subscription enforcement.",
            "dependencies": [
              2,
              5
            ],
            "details": "Modify relevant API endpoints to call trial status middleware and block actions for expired trials. Ensure consistency with subscription-enforcement.ts and maintain access for allowed endpoints during trial.",
            "status": "done",
            "testStrategy": "API test: call endpoints with active and expired trials, verify correct enforcement and error handling.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T14:45:17.312Z"
          },
          {
            "id": 7,
            "title": "Comprehensive Testing of Trial System Functionality",
            "description": "Design and execute tests covering all trial states, UI flows, middleware, and integration points.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5,
              6
            ],
            "details": "Develop test cases for: new registration, trial countdown, trial expiration, upgrade flow, API enforcement, and edge cases. Use both automated and manual testing to validate system robustness.",
            "status": "done",
            "testStrategy": "Automated and manual tests: create accounts, manipulate trial dates, verify UI and API behavior, test upgrade and enforcement logic.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T14:45:18.275Z"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 7,
        "expansionPrompt": "Expand the trial system into: (1) database schema/migration, (2) trial status middleware, (3) trial expired page, (4) dashboard trial banner, (5) signup flow integration, (6) API/middleware integration, (7) comprehensive testing.",
        "updatedAt": "2025-10-08T14:45:18.275Z"
      },
      {
        "id": "50",
        "title": "Implement Card-Required Signup Flow",
        "description": "Create onboarding pages with Stripe Checkout integration requiring card collection for 14-day trial with automatic subscription conversion.",
        "details": "Implement comprehensive card-required signup flow with trial period support:\n\n**1. Create Onboarding Pages:**\n- Create /onboarding/select-plan page with pricing plans display using existing SUBSCRIPTION_PLANS configuration\n- Create /onboarding/payment page with Stripe Checkout integration\n- Use existing UI components from PricingSection and subscription system\n\n**2. Database Schema Updates:**\n- Add trial_status enum column to developers table: ('active', 'expired', 'converted', 'cancelled')\n- Ensure trial_ends_at timestamp exists (already in schema)\n- Add subscription tracking columns: current_period_end, subscription_status with enum ('trialing', 'active', 'inactive', 'cancelled', 'expired', 'past_due')\n- Update RLS policies to handle trial users\n\n**3. Enhanced Stripe Checkout Configuration:**\n- Modify existing /api/stripe/create-checkout-session/route.ts to support trial_period_days: 14\n- Add payment_method_collection: 'always' to ensure card is collected upfront\n- Configure automatic subscription start after trial ends\n- Add trial-specific metadata to sessions and subscriptions\n\n**4. Webhook Handlers for Trial Events:**\n- Extend existing /api/stripe/webhook/route.ts and handleStripeWebhook function\n- Handle customer.subscription.trial_will_end event (3 days before trial ends)\n- Handle customer.subscription.updated for trial to active conversion\n- Handle invoice.payment_failed for failed trial conversions\n- Update developers table with trial_status and subscription_status changes\n\n**5. Signup Flow Integration:**\n- Redirect new signups to /onboarding/select-plan instead of dashboard\n- Update authentication flow in auth callback to check if onboarding is complete\n- Set trial_status='active' and trial_ends_at=NOW() + INTERVAL '14 days' for new registrations\n- Ensure existing subscription middleware works with trial users\n\n**6. Trial User Experience:**\n- Update existing dashboard to show trial countdown banner\n- Allow full feature access during trial period\n- Implement trial-expired page with upgrade prompts\n- Send trial reminder emails using existing email system",
        "testStrategy": "Test complete signup flow: 1) Create new account and verify redirect to /onboarding/select-plan, 2) Select plan and verify Stripe Checkout requires card with trial_period_days=14, 3) Complete checkout and verify trial_status='active' and trial_ends_at is 14 days from now, 4) Test webhook handling for trial events using Stripe CLI, 5) Verify dashboard shows trial banner with correct countdown, 6) Test trial expiration by manually updating trial_ends_at to past date, 7) Verify automatic subscription activation after trial ends, 8) Test failed payment handling during trial conversion, 9) Ensure existing subscription limits work correctly for trial users, 10) Test email notifications for trial events",
        "status": "done",
        "dependencies": [
          "49"
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Develop Onboarding Pages for Plan Selection and Payment",
            "description": "Create onboarding pages for selecting a subscription plan and entering payment details using Stripe Checkout.",
            "dependencies": [],
            "details": "Implement /onboarding/select-plan to display pricing plans using SUBSCRIPTION_PLANS and PricingSection components. Build /onboarding/payment with Stripe Checkout integration, leveraging existing UI components for consistency.",
            "status": "pending",
            "testStrategy": "Verify navigation between onboarding pages, correct plan display, and Stripe Checkout launch with required parameters.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Update Database Schema for Trial and Subscription Tracking",
            "description": "Modify the developers table to support trial status, subscription status, and relevant timestamps for trial management.",
            "dependencies": [],
            "details": "Add trial_status enum column, ensure trial_ends_at exists, add current_period_end and subscription_status columns. Update RLS policies to support trial users and subscription lifecycle.",
            "status": "pending",
            "testStrategy": "Run migration scripts, check schema changes, and validate RLS policy enforcement for trial and subscription states.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate Stripe Checkout with Trial and Card Collection Requirements",
            "description": "Configure Stripe Checkout to require card collection for a 14-day trial and automatic subscription conversion.",
            "dependencies": [
              1,
              2
            ],
            "details": "Update /api/stripe/create-checkout-session/route.ts to set trial_period_days=14, payment_method_collection='always', and add trial metadata. Ensure automatic subscription activation post-trial.",
            "status": "pending",
            "testStrategy": "Create checkout sessions, verify card collection is enforced, and confirm trial metadata is present in Stripe Dashboard.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Extend Webhook Handlers for Trial and Subscription Events",
            "description": "Enhance webhook logic to handle trial expiration, conversion, and payment failures, updating user records accordingly.",
            "dependencies": [
              2,
              3
            ],
            "details": "Update /api/stripe/webhook/route.ts and handleStripeWebhook to process customer.subscription.trial_will_end, customer.subscription.updated, and invoice.payment_failed events. Sync trial_status and subscription_status in the database.",
            "status": "pending",
            "testStrategy": "Simulate Stripe webhook events and verify correct updates to developer records and system state.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Integrate Signup Flow with Onboarding and Trial Logic",
            "description": "Redirect new users to onboarding, set trial status, and ensure authentication and subscription middleware support trial users.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Update signup and authentication flows to redirect to /onboarding/select-plan, set trial_status='active' and trial_ends_at, and verify middleware compatibility with trial accounts.",
            "status": "pending",
            "testStrategy": "Register new users, confirm onboarding redirect, and validate trial status and middleware behavior.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Enhance Trial User Experience in Dashboard and Onboarding",
            "description": "Provide trial countdown, full feature access, trial-expired page, and upgrade prompts for trial users.",
            "dependencies": [
              5
            ],
            "details": "Update dashboard to show trial countdown banner, allow feature access during trial, implement trial-expired page, and display upgrade prompts when trial ends.",
            "status": "pending",
            "testStrategy": "Log in as trial user, verify countdown, access features, and test trial-expired flow and upgrade prompts.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Implement Email Notification Triggers for Trial Lifecycle",
            "description": "Configure email system to send trial reminders, conversion, and re-engagement emails at key trial stages.",
            "dependencies": [
              4,
              5
            ],
            "details": "Use existing email infrastructure to send trial reminder emails (e.g., 3 days before trial ends), conversion success, and failed conversion notifications. Ensure unsubscribe functionality is present.",
            "status": "pending",
            "testStrategy": "Trigger trial stage changes and verify correct email templates are sent to users at each stage.",
            "parentId": "undefined"
          },
          {
            "id": 8,
            "title": "Perform End-to-End Testing of Card-Required Signup Flow",
            "description": "Test the complete signup, trial, and subscription conversion flow to ensure reliability and correct state transitions.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5,
              6,
              7
            ],
            "details": "Create test accounts, complete onboarding, verify Stripe Checkout, trial status, webhook handling, dashboard experience, and email notifications. Test edge cases and error handling throughout the flow.",
            "status": "pending",
            "testStrategy": "Run manual and automated tests covering all signup, trial, and subscription scenarios, including webhook and email triggers.",
            "parentId": "undefined"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 8,
        "expansionPrompt": "Break down the signup flow into: (1) onboarding pages, (2) database schema updates, (3) Stripe Checkout integration, (4) webhook event handling, (5) signup flow integration, (6) trial user experience updates, (7) email notification triggers, (8) end-to-end testing.",
        "updatedAt": "2025-10-08T15:37:58.316Z"
      },
      {
        "id": "51",
        "title": "Implement Trial Email Automation",
        "description": "Create comprehensive trial email automation system with 5 Resend templates and Vercel Cron jobs for trial stage checking and personalized notifications with unsubscribe functionality.",
        "details": "Implement complete trial email automation system for OTORAPORT based on existing email infrastructure:\n\n**1. Create Trial Email Templates in email-service.ts:**\n- Day 0: Welcome email (use existing sendDeveloperWelcomeEmail as base, enhance with trial-specific content)\n- Day 7: Midway check-in with usage stats and tips\n- Day 11: Warning email with upgrade urgency and feature benefits\n- Day 14 Success: Congratulations on conversion with next steps\n- Day 14 Failed: Re-engagement email with special offer and retention messaging\n\n**2. Database Schema Enhancements:**\n- Add trial_stage enum to developers table: ('day_0', 'day_7', 'day_11', 'day_14_success', 'day_14_failed', 'completed')\n- Add last_trial_email_sent timestamp to track email timing\n- Ensure trial_ends_at and trial_status columns exist (already in schema)\n\n**3. Create Vercel Cron Job API Routes:**\n- Create /api/cron/trial-checker route (daily at 9:00 AM UTC)\n- Query developers with trial_status='active' and check trial_ends_at dates\n- Determine appropriate email stage based on days remaining\n- Send personalized emails with developer's usage statistics\n- Update trial_stage and last_trial_email_sent after successful sends\n- Add CRON_SECRET authentication like existing weekly-reports cron\n\n**4. Email Personalization Features:**\n- Include developer's current property count and upload activity\n- Show ministry compliance status and XML endpoint availability\n- Add usage tips and feature highlights based on trial progress\n- Include subscription plan recommendations with pricing\n\n**5. Unsubscribe System Integration:**\n- Use existing email_notifications_enabled and notification_frequency columns\n- Add unsubscribe links to all trial emails using existing /api/unsubscribe endpoint\n- Respect user preferences while ensuring transactional emails (Day 0) always send\n- Add trial-specific opt-out tracking\n\n**6. Update vercel.json Configuration:**\n- Add new cron job entry for trial checker alongside existing weekly-reports\n- Configure optimal timing (daily 9:00 AM UTC) for business hours delivery\n\n**7. Error Handling and Logging:**\n- Implement comprehensive error logging for failed email sends\n- Add retry logic for temporary failures\n- Track email delivery success rates for trial campaigns\n- Use existing logEmailFailure function for consistency\n\n**8. Integration with Existing Systems:**\n- Leverage existing Resend configuration and EMAIL_FROM settings\n- Use existing email preference checking system\n- Integrate with current developer database structure\n- Maintain consistency with existing email template styling and branding",
        "testStrategy": "Test trial email automation system comprehensively: 1) Create test developer account and verify Day 0 welcome email sends immediately with trial-specific content, 2) Manually adjust trial_ends_at dates to trigger Day 7, Day 11, and Day 14 emails and verify correct templates send, 3) Test successful subscription conversion triggers Day 14 Success email, 4) Test trial expiry without conversion triggers Day 14 Failed email, 5) Verify cron job authentication works with CRON_SECRET, 6) Test unsubscribe functionality respects email preferences while allowing critical transactional emails, 7) Validate personalized data appears correctly (property counts, usage stats, ministry compliance status), 8) Test email delivery failure handling and retry logic, 9) Verify trial_stage and last_trial_email_sent columns update correctly after each email send, 10) Test timing accuracy with various trial_ends_at scenarios to ensure emails send at appropriate intervals.",
        "status": "done",
        "dependencies": [
          "49",
          "50"
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Develop and Integrate Trial Email Templates with Personalization",
            "description": "Create and implement 5 distinct trial email templates in email-service.ts, ensuring each template is personalized with developer usage data and trial stage context.",
            "dependencies": [],
            "details": "Design and code Day 0, Day 7, Day 11, Day 14 Success, and Day 14 Failed email templates. Use the existing sendDeveloperWelcomeEmail as a base for Day 0, and ensure each template includes personalized content such as property count, upload activity, compliance status, and plan recommendations. Integrate unsubscribe links and ensure transactional emails (Day 0) always send regardless of preferences.",
            "status": "pending",
            "testStrategy": "Send test emails for each template using mock developer data. Verify personalization, correct template selection, and unsubscribe link functionality. Confirm transactional email bypasses opt-out.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Vercel Cron Job for Automated Trial Stage Email Delivery",
            "description": "Create a secure Vercel cron job API route to automate daily trial stage checks and trigger appropriate email sends based on developer trial status and timing.",
            "dependencies": [
              1
            ],
            "details": "Develop /api/cron/trial-checker route with CRON_SECRET authentication. Query developers with active trials, determine current trial stage from trial_ends_at and last_trial_email_sent, and send the correct email template. Update trial_stage and last_trial_email_sent after successful sends. Integrate error handling, retry logic, and logging using logEmailFailure.",
            "status": "pending",
            "testStrategy": "Simulate cron job execution with various developer trial states. Confirm correct emails are sent, trial_stage and last_trial_email_sent are updated, and errors are logged and retried as needed.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Enhance Database Schema and Email Preference Handling for Trial Automation",
            "description": "Update the developers table schema and ensure robust handling of email preferences and unsubscribe logic for trial automation.",
            "dependencies": [
              1
            ],
            "details": "Add trial_stage enum and last_trial_email_sent timestamp to developers table. Ensure trial_ends_at and trial_status columns exist. Integrate email_notifications_enabled and notification_frequency checks into the automation logic, and implement trial-specific opt-out tracking. Ensure all schema changes are backward compatible and documented.",
            "status": "pending",
            "testStrategy": "Run database migrations and verify schema updates. Test opt-out and preference logic by toggling settings and confirming correct email delivery behavior for all trial stages.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on implement trial email automation.",
        "updatedAt": "2025-10-08T15:53:55.570Z"
      },
      {
        "id": "52",
        "title": "Implement Projects (Inwestycje) System",
        "description": "Create comprehensive projects management system with database table, RLS policies, API endpoints, project assignment in upload flow, and subscription-based project limits enforcement.",
        "details": "Implement complete projects system for OTORAPORT allowing developers to organize properties into investment projects:\n\n**1. Database Schema (Supabase Migration):**\n- The projects table already exists in database schema (confirmed in src/types/database.ts:330-400)\n- Ensure projects table has status enum with 'active', 'inactive', 'archived' values\n- Verify RLS policies exist: developers can only CRUD their own projects\n- Confirm properties.project_id foreign key exists (already in schema at line 430, 471, 512)\n- Create database indexes: projects.developer_id, projects.status for performance\n\n**2. Create API Endpoints:**\n- Create src/app/api/projects/route.ts: GET (list all active projects for authenticated developer), POST (create new project with subscription limit validation)\n- Add project validation using existing patterns from properties API routes\n- Integrate with existing subscription-plans.ts functions: canAddProject(), enforceProjectLimit()\n- Use existing authentication patterns from src/app/api/properties/route.ts\n- Return proper TypeScript types matching database schema\n\n**3. Update Upload Flow Integration:**\n- Modify src/app/api/upload/route.ts and src/app/api/upload-parsed/route.ts\n- Add project_id assignment logic to properties during upload\n- Use existing project fetching pattern (already implemented around line 145-165)\n- Ensure existing project_id assignment in propertiesToInsert mapping works correctly\n\n**4. Enforce Subscription Limits:**\n- Use existing subscription-plans.ts: canAddProject() function handles Basic=1, Pro=2, Enterprise=unlimited\n- Implement project limit checks in POST /api/projects before creation\n- Display appropriate error messages for limit violations using existing patterns\n- Integrate with existing subscription enforcement middleware patterns\n\n**5. Project Management UI Integration:**\n- Prepare for future dashboard project selector in upload widget\n- Ensure API responses include project information for frontend consumption\n- Follow existing API response patterns from properties endpoints\n\n**Technology Integration:**\n- Use existing Supabase client patterns from src/lib/supabase/server.ts\n- Follow existing RLS policy patterns from other tables\n- Integrate with subscription-plans.ts system for limit enforcement\n- Use existing TypeScript types from src/types/database.ts",
        "testStrategy": "Test projects system comprehensively: 1) Test POST /api/projects creates new project and verifies subscription limits (Basic plan allows 1 project, Pro allows 2, Enterprise unlimited), 2) Test GET /api/projects returns only developer's active projects with proper filtering, 3) Verify RLS policies prevent unauthorized access to other developers' projects, 4) Test upload flow assigns properties to correct project_id, 5) Validate subscription limit enforcement blocks project creation when limits exceeded, 6) Test project status filtering works correctly, 7) Verify database indexes improve query performance, 8) Test API error handling returns appropriate HTTP status codes and messages",
        "status": "done",
        "dependencies": [
          "47",
          "48"
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Audit and Finalize Projects Database Schema and RLS Policies",
            "description": "Review and update the existing projects table, ensure status enum values, verify RLS policies, confirm foreign keys, and add necessary indexes for performance.",
            "dependencies": [],
            "details": "Check that the projects table includes a status enum with 'active', 'inactive', and 'archived'. Verify that Row Level Security (RLS) policies restrict CRUD operations to the owning developer. Confirm the properties.project_id foreign key is present. Add indexes on projects.developer_id and projects.status to optimize queries. Use Supabase migration scripts and test with the Supabase CLI.",
            "status": "pending",
            "testStrategy": "Run Supabase migrations, inspect schema, and attempt CRUD operations as different users to confirm RLS. Use EXPLAIN ANALYZE to verify index usage.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement and Test Projects API Endpoints with Subscription Enforcement",
            "description": "Develop GET and POST endpoints for projects, integrate subscription plan checks, and ensure proper authentication and validation.",
            "dependencies": [
              1
            ],
            "details": "Create src/app/api/projects/route.ts with GET (list active projects for authenticated developer) and POST (create project with subscription limit validation). Integrate canAddProject() and enforceProjectLimit() from subscription-plans.ts. Use authentication and validation patterns from properties API. Ensure TypeScript types match the database schema and return project info for frontend use.",
            "status": "pending",
            "testStrategy": "Write integration tests for GET and POST endpoints: verify correct filtering, project creation, and error handling for subscription limits. Confirm API responses match expected types.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Integrate Project Assignment in Upload Flow and Enforce Project Limits",
            "description": "Update upload API routes to support project assignment, ensure properties are linked to projects, and enforce subscription-based project limits during uploads.",
            "dependencies": [
              2
            ],
            "details": "Modify src/app/api/upload/route.ts and src/app/api/upload-parsed/route.ts to assign project_id to properties during upload. Use the existing project fetching and assignment logic. Ensure that project limit checks are enforced during uploads, and display appropriate error messages for violations. Prepare API responses to include project information for future UI integration.",
            "status": "pending",
            "testStrategy": "Test property uploads with and without project assignment, verify correct project_id linkage, and confirm enforcement of subscription project limits. Check error handling and API response structure.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on implement projects (inwestycje) system.",
        "updatedAt": "2025-10-08T17:47:51.003Z"
      },
      {
        "id": "53",
        "title": "Implement Additional Projects Billing for Pro Plan",
        "description": "Create Stripe infrastructure for billing additional projects in Pro plan with 50zł/month per project pricing and database tracking.",
        "details": "Implement comprehensive additional projects billing system for Pro plan subscribers:\n\n**1. Database Schema Updates:**\n- Add additional_projects_count column to developers table (integer, default 0)\n- Update RLS policies to include additional projects count in queries\n- Create migration script for schema update\n\n**2. Update calculateMonthlyCost() Function (src/lib/subscription-plans.ts:98-111):**\n- Modify to accept additional_projects_count parameter from database\n- Enhance Pro plan billing logic to include additional projects fee (5000 grosze = 50zł per project)\n- Update calculateBilling() function to display breakdown with additional projects\n\n**3. Create Stripe Price for Additional Project:**\n- Create new Stripe Price object for additional project add-on (50zł/month)\n- Add metadata to identify as 'additional_project' price type\n- Store price ID in environment variables or configuration\n\n**4. Create POST /api/projects/add-additional Endpoint:**\n- Validate user has Pro plan subscription\n- Check current additional_projects_count in developers table\n- Create new Stripe subscription item for additional project\n- Update developers.additional_projects_count in database\n- Return updated billing information and next invoice preview\n\n**5. Enhanced Stripe Subscription Management:**\n- Update createStripeSubscription() in src/lib/stripe.ts to handle line items\n- Implement subscription modification with multiple line items (base plan + additional projects)\n- Add webhook handlers for subscription.updated events to sync additional_projects_count\n- Update handleSubscriptionUpdated() to process line items changes\n\n**6. Integration with Existing Systems:**\n- Update canAddProject() function to check additional_projects_count from database\n- Modify project limit enforcement in upload APIs to include additional projects\n- Update billing calculations in dashboard to show additional projects breakdown\n- Enhance subscription cards to display additional projects pricing",
        "testStrategy": "Test additional projects billing system comprehensively: 1) Create Pro plan developer and verify additional_projects_count defaults to 0, 2) Test POST /api/projects/add-additional creates Stripe subscription item and increments count, 3) Verify calculateMonthlyCost() correctly adds 50zł per additional project for Pro plan, 4) Test webhook handling updates additional_projects_count when subscription changes, 5) Confirm project limits enforcement includes additional projects in calculations, 6) Test subscription modification preserves existing payment method and billing cycle, 7) Verify billing breakdown displays base plan + additional projects separately in dashboard",
        "status": "done",
        "dependencies": [
          "47",
          "48",
          "52"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Update Database Schema and RLS Policies for Additional Projects",
            "description": "Modify the developers table and RLS policies to support tracking and querying additional projects for Pro plan billing.",
            "dependencies": [],
            "details": "Add an additional_projects_count integer column (default 0) to the developers table. Update Row-Level Security (RLS) policies to ensure queries and updates involving additional projects are secure and accurate. Create a migration script to apply these schema changes.",
            "status": "pending",
            "testStrategy": "Run migration and verify the column exists with default value. Test RLS by querying as different users to ensure correct access.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Stripe Price and Subscription Logic for Additional Projects",
            "description": "Create Stripe Price object for additional projects, update backend logic to handle subscription items, and ensure correct billing integration.",
            "dependencies": [
              1
            ],
            "details": "Create a new Stripe Price object (50zł/month) for the additional project add-on and store its price ID securely. Update backend logic to add or modify subscription items for additional projects, ensuring the correct price and metadata are used. Integrate with Stripe's API to manage line items and handle subscription updates.",
            "status": "pending",
            "testStrategy": "Create a test subscription, add additional projects, and verify Stripe invoices reflect correct charges and metadata.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Develop API Endpoint and Billing Calculation Updates",
            "description": "Build API endpoint for adding additional projects, update cost calculation functions, and ensure dashboard/UI reflects new billing structure.",
            "dependencies": [
              2
            ],
            "details": "Implement POST /api/projects/add-additional endpoint to validate Pro plan, increment additional_projects_count, and update Stripe subscription. Modify calculateMonthlyCost() and related functions to include additional projects fee. Update dashboard and subscription cards to display breakdown of base and additional project charges.",
            "status": "pending",
            "testStrategy": "Test endpoint with various scenarios (valid/invalid Pro plan, project limits). Verify UI and cost calculations update correctly after adding projects.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on implement additional projects billing for pro plan.",
        "updatedAt": "2025-10-08T20:29:56.839Z"
      },
      {
        "id": "54",
        "title": "Implement Google Analytics 4 Integration",
        "description": "Set up comprehensive GA4 tracking with property creation, script integration, automatic pageview tracking, custom event tracking for key user actions, and conversion goal configuration.",
        "details": "Implement comprehensive Google Analytics 4 integration for OTORAPORT to track user behavior and business metrics:\n\n**1. GA4 Property Setup:**\n- Create new GA4 property in Google Analytics console for otoraport-v2.vercel.app domain\n- Configure data streams for web tracking\n- Set up enhanced ecommerce tracking for subscription events\n- Generate GA4 Measurement ID (format: G-XXXXXXXXXX)\n\n**2. Environment Configuration:**\n- Add NEXT_PUBLIC_GA4_MEASUREMENT_ID to environment variables and env-validation.ts schema\n- Update src/lib/env-validation.ts to include GA4 configuration validation\n- Add GA4 environment variable to deployment documentation\n\n**3. GA4 Script Integration in Layout:**\n- Add GA4 gtag script to src/app/layout.tsx head section using Next.js Script component\n- Implement gtag configuration with measurement ID from environment variables\n- Enable automatic pageview tracking with enhanced measurement\n- Add consent management configuration for GDPR compliance\n\n**4. Custom Event Tracking Implementation:**\n- Create src/lib/ga4-tracking.ts utility with functions for custom event tracking\n- Implement trackSignup() event for user registration completion\n- Implement trackUploadSuccess() event for successful property data uploads\n- Implement trackSubscriptionStart() event for trial/subscription activation\n- Implement trackSubscriptionConvert() event for trial-to-paid conversions\n- Add user property tracking for subscription plan and trial status\n\n**5. Event Integration in Existing Components:**\n- Add trackSignup() call to successful registration in auth/signup/page.tsx\n- Add trackUploadSuccess() call to successful uploads in upload API routes\n- Add trackSubscriptionStart() call to trial activation in subscription system\n- Add trackSubscriptionConvert() call to successful trial conversions\n- Integrate with existing error tracking to avoid duplicate analytics calls\n\n**6. Conversion Goals Configuration:**\n- Set up conversion goals in GA4: signup completion, first upload, subscription start, trial conversion\n- Configure enhanced ecommerce tracking for subscription revenue\n- Set up custom dimensions for user segment tracking (plan type, trial status)\n- Configure audience definitions for retargeting campaigns\n\n**7. Privacy Compliance:**\n- Update existing CookieBanner component to include GA4 consent controls\n- Implement analytics opt-out functionality in dashboard settings\n- Add GA4 tracking disclosure to privacy policy page\n- Ensure GDPR compliance with consent-based tracking activation",
        "testStrategy": "Test GA4 implementation comprehensively: 1) Verify GA4 script loads correctly on all pages without console errors, 2) Test automatic pageview tracking appears in GA4 real-time reports, 3) Manually trigger signup flow and verify trackSignup() event appears in GA4 events report, 4) Test file upload and verify trackUploadSuccess() custom event tracking, 5) Verify subscription events fire correctly during trial signup process, 6) Test analytics opt-out functionality in dashboard settings, 7) Validate enhanced ecommerce tracking shows subscription revenue data, 8) Confirm conversion goals track properly in GA4 conversions report, 9) Test cookie consent banner integration with GA4 activation, 10) Verify all tracking respects user privacy preferences and GDPR requirements",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Create and Configure GA4 Property for OTORAPORT",
            "description": "Set up a new Google Analytics 4 property for the otoraport-v2.vercel.app domain, including data stream configuration and enhanced measurement settings.",
            "dependencies": [],
            "details": "Access the Google Analytics Admin panel, create a new property named for OTORAPORT, select the appropriate time zone and currency, and configure a web data stream for the domain. Enable enhanced measurement features for automatic tracking of pageviews and common events. Generate and record the GA4 Measurement ID for later integration.",
            "status": "pending",
            "testStrategy": "Verify property creation in GA4 dashboard, confirm data stream is active, and ensure Measurement ID is generated and accessible.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Integrate GA4 Tracking Script and Environment Variables",
            "description": "Add the GA4 gtag script to the Next.js layout, configure environment variables, and enable automatic pageview tracking with GDPR consent management.",
            "dependencies": [
              1
            ],
            "details": "Insert the GA4 gtag script into the src/app/layout.tsx head section using the Next.js Script component. Reference the GA4 Measurement ID from environment variables (NEXT_PUBLIC_GA4_MEASUREMENT_ID), and update env-validation.ts for schema validation. Implement consent management logic to ensure GDPR compliance before activating tracking.",
            "status": "pending",
            "testStrategy": "Check that the GA4 script loads on all pages, verify pageview events appear in GA4 real-time reports, and test consent controls for GDPR compliance.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Custom Event Tracking and Conversion Goals",
            "description": "Develop utility functions for custom event tracking, integrate them into key user flows, and configure conversion goals and audience segments in GA4.",
            "dependencies": [
              2
            ],
            "details": "Create src/lib/ga4-tracking.ts with functions for events like trackSignup(), trackUploadSuccess(), trackSubscriptionStart(), and trackSubscriptionConvert(). Integrate these calls into relevant components and API routes. In GA4, set up conversion goals for signup, upload, subscription start, and trial conversion, and configure custom dimensions and audiences for user segmentation.",
            "status": "pending",
            "testStrategy": "Trigger each custom event and verify appearance in GA4 events report; confirm conversion goals and audience segments are correctly configured and reporting.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on implement google analytics 4 integration.",
        "updatedAt": "2025-10-08T21:24:11.704Z"
      },
      {
        "id": "55",
        "title": "Implement Vercel Analytics and PostHog Integration",
        "description": "Install posthog-js package and integrate with existing Vercel Analytics to track key user events and configure marketing funnels for signup, upload, and payment conversion tracking.",
        "details": "Implement comprehensive analytics integration building on existing Vercel Analytics setup:\n\n**1. PostHog Installation and Configuration:**\n- Install posthog-js package: `npm install posthog-js`\n- Add environment variables to env-validation.ts schema: NEXT_PUBLIC_POSTHOG_KEY and NEXT_PUBLIC_POSTHOG_HOST\n- Update getEnv() function to include PostHog configuration\n\n**2. Create PostHog Provider (src/app/providers.tsx):**\n- Create new providers.tsx file since it doesn't exist yet\n- Initialize PostHog client with proper configuration (EU hosting, privacy settings)\n- Export PostHogProvider component and usePostHog hook\n- Configure automatic pageview tracking disabled (manual control)\n\n**3. Update Root Layout Integration:**\n- Import PostHogProvider in src/app/layout.tsx (existing file has Vercel Analytics already)\n- Wrap children with PostHogProvider while keeping existing Analytics and SpeedInsights components\n- Ensure PostHog loads after user consent for GDPR compliance\n\n**4. Event Tracking Implementation:**\n- Create src/lib/analytics-events.ts with typed event tracking functions\n- Implement key events: trackSignup(), trackLogin(), trackFileUpload(), trackSubscriptionStart(), trackTrialStart(), trackPaymentSuccess()\n- Add event tracking to existing API routes: /api/auth/callback, /api/upload, /api/stripe/webhook\n- Use existing React hooks pattern from codebase (similar to use-auth-simple.ts)\n\n**5. Marketing Funnels Configuration:**\n- Set up conversion funnels in PostHog dashboard: Signup → Upload → Trial → Paid\n- Configure cohort analysis for trial-to-paid conversion tracking\n- Create custom events for key business metrics: property_uploaded, subscription_activated, trial_converted\n- Add UTM parameter tracking for marketing attribution\n\n**6. Privacy and Compliance:**\n- Integrate with existing CookieBanner.tsx component for analytics consent\n- Respect user privacy preferences stored in localStorage\n- Configure PostHog with privacy-first settings (no automatic geolocation, IP anonymization)\n- Update privacy policy page to include PostHog data processing disclosure",
        "testStrategy": "Test analytics implementation comprehensively: 1) Verify PostHog provider loads correctly without console errors and respects cookie consent settings, 2) Test event tracking by manually triggering signup flow and confirming events appear in PostHog live events, 3) Verify file upload tracking sends property_uploaded event with correct metadata, 4) Test subscription events fire correctly during Stripe webhook processing, 5) Confirm Vercel Analytics continues working alongside PostHog without conflicts, 6) Test funnel tracking shows complete user journey from signup to payment, 7) Verify privacy compliance by testing with analytics cookies disabled and confirming no PostHog data is sent, 8) Test UTM parameter capture and attribution tracking for marketing campaigns",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Install and Configure PostHog with Vercel Analytics",
            "description": "Install the posthog-js package, set up environment variables, and configure PostHog initialization alongside existing Vercel Analytics.",
            "dependencies": [],
            "details": "Run `npm install posthog-js`. Add NEXT_PUBLIC_POSTHOG_KEY and NEXT_PUBLIC_POSTHOG_HOST to your env-validation.ts schema and .env files. Update getEnv() to include PostHog config. Ensure Vercel Analytics is enabled and configured per project requirements. Verify both analytics providers are initialized correctly and do not conflict.",
            "status": "pending",
            "testStrategy": "Check that both PostHog and Vercel Analytics scripts load without errors. Confirm environment variables are present and correct. Validate initial analytics events are sent to both platforms.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement PostHog Provider and Integrate with App Layout",
            "description": "Create a PostHogProvider component, configure privacy settings, and wrap the app layout to enable event tracking while respecting user consent.",
            "dependencies": [
              1
            ],
            "details": "Create src/app/providers.tsx and initialize PostHog client with EU hosting and privacy-first settings. Export PostHogProvider and usePostHog hook. Import PostHogProvider in src/app/layout.tsx and wrap children, ensuring Vercel Analytics and SpeedInsights remain. Integrate with CookieBanner.tsx to load PostHog only after user consent for GDPR compliance.",
            "status": "pending",
            "testStrategy": "Verify PostHogProvider loads only after consent. Confirm no analytics events are sent before consent. Check that pageview and custom events are tracked after consent and appear in PostHog dashboard.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implement Key Event Tracking and Marketing Funnel Configuration",
            "description": "Create typed event tracking functions, add event hooks to API routes, and configure marketing funnels and attribution in PostHog dashboard.",
            "dependencies": [
              2
            ],
            "details": "Create src/lib/analytics-events.ts with functions for signup, login, upload, trial start, subscription, and payment success. Add event tracking to /api/auth/callback, /api/upload, and /api/stripe/webhook. Set up conversion funnels and cohort analysis in PostHog dashboard. Track UTM parameters for marketing attribution and create custom events for business metrics.",
            "status": "pending",
            "testStrategy": "Trigger each event manually and verify appearance in PostHog live events. Confirm funnel steps and cohort analysis work as expected. Test UTM parameter tracking by visiting with different campaign links.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on implement vercel analytics and posthog integration.",
        "updatedAt": "2025-10-09T06:19:40.662Z"
      },
      {
        "id": "56",
        "title": "Implement Price History Tracking",
        "description": "Create comprehensive price history tracking system with database table, RLS policies, automatic trigger tracking, API endpoint, and Recharts visualization component.",
        "details": "Implement complete price history tracking system for OTORAPORT allowing developers to track property price changes over time:\n\n**1. Database Schema (Supabase Migration):**\n- Create price_history table with columns: id (uuid), property_id (uuid), developer_id (uuid), old_base_price (numeric), new_base_price (numeric), old_final_price (numeric), new_final_price (numeric), old_price_per_m2 (numeric), new_price_per_m2 (numeric), change_reason (text), changed_at (timestamp), created_by (uuid)\n- Add RLS policies: developers can only view/insert their own price history records\n- Create foreign key constraints to properties and developers tables\n- Add indexes on property_id, developer_id, and changed_at for optimal query performance\n\n**2. Database Trigger Creation:**\n- Create track_price_change() PostgreSQL function that automatically inserts price_history record when properties table is updated\n- Trigger should only fire when base_price, final_price, or price_per_m2 columns change\n- Function should capture old and new values and set changed_at to current timestamp\n- Include change_reason parameter support from existing update_property_price() function (line 592-601 in database.ts)\n\n**3. API Endpoint Development:**\n- Create GET /api/properties/[id]/price-history endpoint following existing API patterns in src/app/api/properties/[id]/route.ts\n- Implement pagination support with default limit of 50 records\n- Add filtering by date range (from/to query parameters)\n- Include proper error handling and RLS enforcement\n- Return price changes sorted by changed_at DESC (newest first)\n- Use existing database connection patterns from src/lib/supabase/server.ts\n\n**4. PriceHistoryChart Component:**\n- Install recharts package: npm install recharts @types/recharts\n- Create src/components/dashboard/price-history-chart.tsx using Recharts LineChart\n- Display price changes over time with multiple lines (base_price, final_price, price_per_m2)\n- Include hover tooltips showing exact values and change dates\n- Add responsive design following existing component patterns in src/components/dashboard/\n- Include loading states and error handling with existing UI components\n- Format prices using Polish złoty formatting\n\n**5. Property Detail Page Integration:**\n- Enhance existing property detail functionality to include price history tab\n- Use existing @radix-ui/react-tabs from package.json for tab navigation\n- Create new tab alongside existing property information\n- Integrate PriceHistoryChart component within tab content\n- Add data fetching hook using SWR pattern from existing components\n- Follow existing UI patterns from src/components/dashboard/ directory",
        "testStrategy": "Test price history system comprehensively: 1) Create price_history table and verify RLS policies allow only developer's own records, 2) Test track_price_change() trigger by updating property prices via existing API and confirming history records are automatically created, 3) Verify GET /api/properties/[id]/price-history endpoint returns proper pagination and filtering, 4) Test PriceHistoryChart component renders correctly with sample data and handles empty states, 5) Confirm price history tab integration works in property detail view with proper loading and error states, 6) Validate trigger only fires when price fields actually change (not on other property updates), 7) Test foreign key constraints prevent orphaned records when properties are deleted",
        "status": "done",
        "dependencies": [
          "39"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Implement Price History Database Schema with RLS and Triggers",
            "description": "Create the price_history table, set up row-level security (RLS) policies, and implement a PostgreSQL trigger function to automatically track price changes.",
            "dependencies": [],
            "details": "Define the price_history table with all required columns and foreign key constraints. Add indexes on property_id, developer_id, and changed_at. Implement RLS policies so developers can only access their own records. Write the track_price_change() trigger function to insert a new price_history record whenever relevant price fields change in the properties table, capturing old/new values, change_reason, and changed_at.",
            "status": "pending",
            "testStrategy": "Run migrations and verify table structure, RLS enforcement, and trigger behavior by updating property prices and confirming correct history records are created.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Develop Price History API Endpoint with Pagination and Filtering",
            "description": "Create a REST API endpoint to fetch price history for a property, supporting pagination, date filtering, and proper error handling.",
            "dependencies": [
              1
            ],
            "details": "Implement GET /api/properties/[id]/price-history using existing API patterns. Support pagination (default 50 records) and date range filtering via query parameters. Ensure results are sorted by changed_at DESC. Enforce RLS and handle errors gracefully. Use the established database connection utilities.",
            "status": "pending",
            "testStrategy": "Test endpoint with various parameters, verify correct data, pagination, filtering, and RLS enforcement. Check error responses for invalid or unauthorized requests.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Build and Integrate Price History Visualization Component",
            "description": "Create a Recharts-based PriceHistoryChart component and integrate it into the property detail page with tab navigation and data fetching.",
            "dependencies": [
              2
            ],
            "details": "Install recharts and types. Build PriceHistoryChart in src/components/dashboard/price-history-chart.tsx to display base_price, final_price, and price_per_m2 over time with tooltips and responsive design. Add a new tab to the property detail page using @radix-ui/react-tabs, fetch data with SWR, and handle loading/error states. Format prices in Polish złoty.",
            "status": "pending",
            "testStrategy": "Render the chart with mock and real data, verify correct lines, tooltips, and formatting. Test integration in the property detail page, including tab switching and data loading.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on implement price history tracking.",
        "updatedAt": "2025-10-09T06:53:42.630Z"
      },
      {
        "id": "57",
        "title": "Build Admin Panel with User Management",
        "description": "Create comprehensive admin panel for managing users, subscriptions, and system oversight",
        "details": "Create admin_roles table with RBAC permissions, implement requireAdmin() middleware checking user admin status, build /admin/dashboard protected route with admin layout, create /admin/users page listing all users with search/filter/pagination, implement GET /api/admin/users endpoint, add chudziszewski221@gmail.com as super_admin, display user data: email, subscription plan, properties count, created_at, status",
        "testStrategy": "Test admin access control (non-admins get 403), verify admin user list with search and filtering, test pagination functionality, validate RBAC permissions system, ensure super_admin has full access",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Implement RBAC System for Admin Panel",
            "description": "Create an admin_roles table and set up role-based access control (RBAC) to manage user permissions within the admin panel.",
            "dependencies": [],
            "details": "Define clear admin roles and responsibilities based on organizational needs. Implement the admin_roles table to store roles and permissions. Use a roles and permissions matrix to map out access levels. Ensure the principle of least privilege is enforced so users only have necessary permissions. Document all roles and permissions for audit and future maintenance.",
            "status": "done",
            "testStrategy": "Verify that users are assigned correct roles and permissions. Test that only authorized users can access admin features. Review audit logs for role changes.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T13:42:44.420Z"
          },
          {
            "id": 2,
            "title": "Develop Admin Middleware and Protected Routes",
            "description": "Implement requireAdmin() middleware to check user admin status and protect admin routes such as /admin/dashboard and /admin/users.",
            "dependencies": [
              1
            ],
            "details": "Create middleware that validates user admin status before granting access to protected admin routes. Integrate this middleware with /admin/dashboard and /admin/users endpoints. Ensure that non-admin users receive a 403 Forbidden response when attempting to access these routes. Add chudziszewski221@gmail.com as super_admin with full access.",
            "status": "done",
            "testStrategy": "Test access control by attempting to access protected routes with non-admin and admin accounts. Confirm super_admin has unrestricted access.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T13:42:45.345Z"
          },
          {
            "id": 3,
            "title": "Build User Management Interface and API Endpoints",
            "description": "Create the /admin/users page with user listing, search, filter, and pagination. Implement GET /api/admin/users endpoint to serve user data.",
            "dependencies": [
              2
            ],
            "details": "Develop a user management UI that lists all users with search, filter, and pagination features. Display user data including email, subscription plan, properties count, created_at, and status. Build the GET /api/admin/users endpoint to provide this data securely. Ensure the interface is intuitive and supports efficient user management.",
            "status": "done",
            "testStrategy": "Test user listing, search, filter, and pagination functionalities. Validate that user data is displayed correctly and securely. Confirm API endpoint returns accurate data.",
            "parentId": "undefined",
            "updatedAt": "2025-10-08T13:42:46.256Z"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on build admin panel with user management.",
        "updatedAt": "2025-10-08T13:42:46.256Z"
      },
      {
        "id": "58",
        "title": "Implement Bulk Delete with Cache Invalidation",
        "description": "Add bulk delete functionality for properties with proper cache invalidation for ministry endpoints",
        "details": "Create POST /api/properties/bulk-delete endpoint accepting { propertyIds: string[] }, implement transactional delete (all or nothing), add cache revalidation for XML/CSV/MD5 endpoints after delete operations, build 'Delete Selected' button in Properties Table with confirmation modal showing preview of deletion count",
        "testStrategy": "Test bulk delete with 1-100 properties, verify transaction atomicity (all deleted or none), confirm cache invalidation updates XML/CSV/MD5 endpoints, test confirmation modal displays correct count, validate success toast notifications",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Develop Bulk Delete API Endpoint with Transactional Logic",
            "description": "Implement the POST /api/properties/bulk-delete endpoint to accept an array of property IDs and perform a transactional (all-or-nothing) delete operation.",
            "dependencies": [],
            "details": "Create a new API endpoint that accepts a payload like { propertyIds: string[] }. Ensure the deletion is performed within a database transaction so that either all specified properties are deleted or none are, maintaining data integrity. Handle validation, permissions, and error responses according to API best practices.",
            "status": "pending",
            "testStrategy": "Send requests with various property ID arrays (including invalid IDs) and verify that either all specified properties are deleted or none are, with appropriate error handling.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Cache Invalidation for Ministry Endpoints After Bulk Delete",
            "description": "Ensure that after a successful bulk delete, caches for XML, CSV, and MD5 endpoints related to properties are invalidated or revalidated.",
            "dependencies": [
              1
            ],
            "details": "Integrate cache invalidation logic into the bulk delete endpoint so that, upon successful deletion, any cached data for ministry endpoints (XML, CSV, MD5) is cleared or refreshed. This ensures that subsequent requests reflect the updated property data.",
            "status": "pending",
            "testStrategy": "After performing a bulk delete, verify that the XML, CSV, and MD5 endpoints return updated data and do not serve stale cache.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Build UI Integration: 'Delete Selected' Button with Confirmation Modal",
            "description": "Add a 'Delete Selected' button to the Properties Table UI, including a confirmation modal that previews the number of properties to be deleted.",
            "dependencies": [
              1,
              2
            ],
            "details": "Update the frontend to allow users to select multiple properties and trigger the bulk delete operation. Implement a confirmation modal that displays the count of properties to be deleted and requires user confirmation before proceeding. Ensure the UI handles success and error states gracefully.",
            "status": "pending",
            "testStrategy": "Select multiple properties in the UI, trigger the delete action, confirm the modal displays the correct count, and verify that the UI updates appropriately after deletion.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on implement bulk delete with cache invalidation.",
        "updatedAt": "2025-10-09T06:37:44.967Z"
      },
      {
        "id": "59",
        "title": "Implement Analytics Integration (GA4, Vercel Analytics, PostHog)",
        "description": "CANCELLED - Task cancelled as duplicate. All analytics implementations already completed in separate tasks: Task #54 (GA4) and Task #55 (PostHog + Vercel Analytics). All analytics packages installed, configured, and actively tracking events.",
        "status": "cancelled",
        "dependencies": [],
        "priority": "medium",
        "details": "This task is cancelled as it was identified as a duplicate of existing implementations. Based on codebase analysis:\n\n**Already Implemented:**\n- GA4 integration complete (Task #54) - configured in src/app/layout.tsx with consent mode\n- PostHog integration complete (Task #55) - initialized in src/app/providers.tsx\n- Vercel Analytics installed and active in src/app/layout.tsx\n- Event tracking functions implemented in src/lib/ga4-tracking.ts and src/lib/analytics-events.ts\n- GDPR-compliant consent management working\n\n**Current State:**\n- @vercel/analytics@1.5.0 and posthog-js@1.273.1 installed in package.json\n- GA4 script loads conditionally with NEXT_PUBLIC_GA4_MEASUREMENT_ID\n- PostHog configured for EU hosting (GDPR compliance)\n- Custom event tracking for signup, upload, subscription events\n- Cookie consent integration working\n\nAll original task requirements have been fulfilled through separate task implementations.",
        "testStrategy": "All testing completed in original tasks. Current implementation verified: GA4 tracking active with consent mode, PostHog events firing correctly with opt-in/opt-out functionality, Vercel Analytics reporting Core Web Vitals, and custom conversion funnels working.",
        "subtasks": [
          {
            "id": 1,
            "title": "Mark as duplicate - GA4 already implemented in Task #54",
            "description": "GA4 integration already completed with full tracking, consent mode, and event functions in src/lib/ga4-tracking.ts",
            "dependencies": [],
            "details": "Task #54 fully implemented GA4 with:\n- Script injection in src/app/layout.tsx with NEXT_PUBLIC_GA4_MEASUREMENT_ID\n- GDPR-compliant consent mode (analytics_storage: denied by default)\n- Custom event tracking functions (trackSignup, trackUploadSuccess, trackSubscriptionStart, trackSubscriptionConvert)\n- User properties and conversion tracking\n- Cookie consent integration",
            "status": "completed",
            "testStrategy": "GA4 implementation verified - tracking active, events firing, consent respected",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Mark as duplicate - Vercel Analytics already active",
            "description": "Vercel Analytics already installed and configured in the application layout for Core Web Vitals monitoring",
            "dependencies": [],
            "details": "Vercel Analytics implemented:\n- @vercel/analytics@1.5.0 installed in package.json\n- <Analytics /> component active in src/app/layout.tsx\n- @vercel/speed-insights also configured for performance monitoring\n- No additional configuration needed - works automatically with Vercel deployment",
            "status": "completed",
            "testStrategy": "Vercel Analytics active - Core Web Vitals reporting to Vercel dashboard",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Mark as duplicate - PostHog already implemented in Task #55",
            "description": "PostHog integration already completed with full event tracking, funnels, and GDPR compliance in src/app/providers.tsx",
            "dependencies": [],
            "details": "Task #55 fully implemented PostHog with:\n- posthog-js@1.273.1 installed and initialized in PostHogProvider\n- EU hosting for GDPR compliance (https://eu.i.posthog.com)\n- Event tracking functions in src/lib/analytics-events.ts\n- Custom events: user_signup, file_upload, subscription_start, trial_start, payment_success\n- Cookie consent integration with opt-in/opt-out functionality\n- User identification and property tracking",
            "status": "completed",
            "testStrategy": "PostHog implementation verified - events tracking, funnels working, consent respected",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on implement analytics integration (ga4, vercel analytics, posthog)."
      },
      {
        "id": "60",
        "title": "Build Admin Analytics Dashboard with Revenue and User KPIs",
        "description": "Create the /admin/analytics page featuring MRR/ARR revenue charts, user growth visualizations, and KPI cards (total users, MRR, churn rate, trial conversion), and implement the supporting GET /api/admin/analytics endpoint.",
        "details": "1. **API Endpoint Implementation:**\n   - Design and implement GET /api/admin/analytics to aggregate and return analytics data: monthly recurring revenue (MRR), annual recurring revenue (ARR), total users, churn rate, trial conversion rate, and user growth over time.\n   - Query and aggregate data from subscriptions, users, and trials tables, ensuring efficient SQL queries and proper access control (admin-only, using requireAdmin middleware from Task 57).\n   - Structure the API response for easy consumption by the frontend (e.g., { mrr, arr, totalUsers, churnRate, trialConversion, userGrowth: [{month, count}], revenueGrowth: [{month, mrr, arr}] }).\n   - Ensure sensitive data is not exposed and all calculations (e.g., churn rate, trial conversion) follow SaaS best practices.\n\n2. **Frontend Dashboard Page (/admin/analytics):**\n   - Use a modern React UI library (e.g., MUI, Tremor, or Ant Design) for rapid development and consistent styling[1][2][5][8].\n   - Build a responsive grid layout with KPI cards at the top (total users, MRR, churn rate, trial conversion), using loading skeletons and error states.\n   - Implement interactive charts for MRR/ARR revenue and user growth using a charting library (e.g., Tremor, Nivo, or Recharts)[2][3][5].\n   - Fetch analytics data from the new API endpoint with SWR or React Query for caching and revalidation.\n   - Ensure the page is protected by admin authentication and RBAC (leveraging requireAdmin middleware).\n   - Follow accessibility and responsive design best practices.\n\n3. **Best Practices & Considerations:**\n   - Use server-side aggregation for performance and security.\n   - Memoize expensive calculations and cache results where appropriate.\n   - Document API schema and frontend data contracts.\n   - Add unit and integration tests for both backend and frontend components.\n   - Prepare for future extensibility (e.g., additional KPIs, export functionality).\n\n**References:**\n- Use Tremor or MUI for KPI cards and charts for rapid, visually appealing dashboards[1][2][5][8].\n- See [freeCodeCamp][2] and [YouTube][3] tutorials for full-stack analytics dashboard patterns.",
        "testStrategy": "1. **API Testing:**\n   - Call GET /api/admin/analytics as an admin and verify the response includes accurate MRR, ARR, total users, churn rate, trial conversion, and time-series data.\n   - Attempt access as a non-admin and confirm a 403 response.\n   - Validate calculations against known database values (e.g., compare MRR/ARR to Stripe or billing data).\n\n2. **Frontend Testing:**\n   - Visit /admin/analytics as an admin and verify all KPI cards and charts render with correct, up-to-date data.\n   - Test loading and error states by simulating slow or failed API responses.\n   - Confirm responsive layout on mobile and desktop.\n   - Check accessibility (keyboard navigation, ARIA labels).\n\n3. **Integration Testing:**\n   - Change underlying data (e.g., add/cancel subscriptions, new users) and verify dashboard updates accordingly.\n   - Test cache invalidation and data refresh.\n\n4. **Security Testing:**\n   - Ensure only admins can access the page and API endpoint.\n   - Attempt unauthorized access and confirm proper error handling.",
        "status": "done",
        "dependencies": [
          "57"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Implement GET /api/admin/analytics Endpoint",
            "description": "Create a secure, admin-only API endpoint that aggregates and returns analytics data for MRR, ARR, total users, churn rate, trial conversion, and user/revenue growth over time.",
            "dependencies": [
              57
            ],
            "details": "Design efficient SQL queries to aggregate data from subscriptions, users, and trials tables. Implement proper access control using requireAdmin middleware. Structure the API response for easy frontend consumption, ensuring sensitive data is protected and calculations follow SaaS best practices. Document the API schema and data contracts.",
            "status": "pending",
            "testStrategy": "Call the endpoint as an admin and verify response accuracy. Attempt access as a non-admin and confirm 403. Validate calculations against known database states. Write unit and integration tests for the endpoint.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Build Responsive /admin/analytics Dashboard Page",
            "description": "Develop a modern, accessible React dashboard page displaying KPI cards and interactive charts for revenue and user growth metrics.",
            "dependencies": [
              1
            ],
            "details": "Use a React UI library (e.g., MUI, Tremor, Ant Design) for consistent styling. Implement a responsive grid layout with KPI cards (total users, MRR, churn rate, trial conversion) at the top. Add loading skeletons and error states. Integrate interactive charts (MRR/ARR, user growth) using a charting library (e.g., Tremor, Nivo, Recharts). Fetch data from the new API using SWR or React Query. Protect the page with admin authentication and RBAC. Follow accessibility and responsive design best practices.",
            "status": "pending",
            "testStrategy": "Test page responsiveness across devices. Verify KPI cards and charts render correctly with mock and live data. Check admin access controls. Validate loading and error states. Conduct accessibility audits.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Ensure Performance, Security, and Extensibility",
            "description": "Optimize dashboard performance, enforce security, document components, and prepare for future feature expansion.",
            "dependencies": [
              1,
              2
            ],
            "details": "Use server-side aggregation for performance and security. Memoize expensive calculations and implement caching where appropriate. Document API and frontend data contracts. Add unit and integration tests for both backend and frontend. Design the dashboard layout and data flow to support future KPIs and export functionality. Review and refine based on dashboard design best practices for hierarchy, clarity, and user experience[1][2][3].",
            "status": "pending",
            "testStrategy": "Profile API and frontend performance under load. Verify caching and memoization work as expected. Review documentation for completeness. Test adding a new KPI or export feature to confirm extensibility.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on build admin analytics dashboard with revenue and user kpis.",
        "updatedAt": "2025-10-09T08:17:54.611Z"
      },
      {
        "id": "61",
        "title": "Implement Subdomain System for Pro Plan",
        "description": "Add subdomain support for Pro plan developers, including database schema changes, subdomain availability checks, Vercel wildcard configuration, public property pages, and custom branding.",
        "details": "1. **Database Schema Update:**\n   - Add a `subdomain` (VARCHAR, unique, nullable) column to the `developers` table via a migration. Enforce uniqueness at the database level and update RLS policies to ensure only the owning developer can modify their subdomain.\n   \n2. **Subdomain Availability Checker:**\n   - Implement an API endpoint (e.g., `POST /api/subdomain/check`) that validates subdomain format (alphanumeric, 3-32 chars, no reserved words), checks for uniqueness, and returns availability status. Use server-side validation to prevent race conditions.\n   - Integrate this checker into the onboarding and settings UI for Pro plan users, providing real-time feedback.\n\n3. **Vercel Wildcard Domain Configuration:**\n   - Update Vercel project settings to add a wildcard domain: `*.otoraport.pl`.\n   - Ensure Next.js rewrites and middleware correctly route requests based on the subdomain (e.g., `subdomain.otoraport.pl`). Use Next.js middleware to extract the subdomain from the host header and inject it into the request context.\n   - Update environment variables and deployment documentation to reflect the new domain setup.\n\n4. **Public Developer Property Pages:**\n   - Create a public route (e.g., `/[subdomain]`) that displays the developer's properties, using SSR/ISR for performance and SEO. Fetch properties based on the developer's subdomain, enforcing only public/active listings are shown.\n   - Design the page to be mobile-responsive and SEO-friendly, including Open Graph tags and sitemap updates.\n\n5. **Custom Branding (Logo, Colors):**\n   - Extend the `developers` table to include `branding_logo_url` and `branding_colors` (JSON or text) columns.\n   - Update the onboarding/settings UI to allow Pro users to upload a logo (with image validation and CDN storage) and select primary/secondary colors (with color picker UI).\n   - On public property pages, dynamically apply the developer's branding (logo in header, colors for primary UI elements) using CSS variables or a theming system.\n\n**Best Practices:**\n- Use atomic transactions for subdomain assignment to prevent race conditions.\n- Validate subdomain DNS compatibility (no underscores, etc.).\n- Ensure all public pages are protected against XSS and injection attacks.\n- Use feature flags to restrict subdomain features to Pro plan users only.\n- Write comprehensive unit and integration tests for subdomain logic and public page rendering.",
        "testStrategy": "1. **Database:**\n   - Verify the `subdomain` column exists, is unique, and RLS policies are enforced.\n   - Attempt to assign duplicate subdomains and confirm rejection.\n\n2. **API:**\n   - Test subdomain availability endpoint with valid, invalid, and taken subdomains.\n   - Simulate concurrent requests to ensure no duplicates are assigned.\n\n3. **Vercel/Wildcard:**\n   - Deploy to staging and verify that requests to `subdomain.otoraport.pl` route to the correct developer's public page.\n   - Confirm rewrites/middleware extract subdomain correctly in all environments.\n\n4. **Public Pages:**\n   - Access public property pages via subdomain and confirm correct properties and branding are displayed.\n   - Test SEO tags and mobile responsiveness.\n   - Ensure only public/active properties are shown.\n\n5. **Branding:**\n   - Upload various logo formats and select colors; verify branding is applied on public pages.\n   - Test fallback behavior when branding is missing.\n\n6. **Security:**\n   - Attempt XSS and injection attacks on subdomain and branding fields; verify sanitization.\n\n7. **Feature Restriction:**\n   - Confirm only Pro plan users can set subdomains and branding; downgrade to Basic and verify feature is disabled.",
        "status": "done",
        "dependencies": [
          "52"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Update Database Schema and RLS Policies for Subdomain and Branding",
            "description": "Modify the developers table to support subdomains and custom branding, ensuring data integrity and access control.",
            "dependencies": [],
            "details": "Add a unique, nullable VARCHAR column 'subdomain' to the developers table. Enforce uniqueness at the database level. Extend the table with 'branding_logo_url' and 'branding_colors' columns. Update Row-Level Security (RLS) policies so only the owning developer can modify their subdomain and branding fields. Use atomic transactions for subdomain assignment to prevent race conditions.",
            "status": "pending",
            "testStrategy": "Verify schema changes via migration. Attempt to assign duplicate subdomains and confirm rejection. Test RLS by attempting unauthorized updates. Check branding fields for correct storage and retrieval.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement Subdomain Availability API and Integrate with Pro UI",
            "description": "Create an API endpoint for subdomain validation and integrate it into onboarding/settings for Pro users.",
            "dependencies": [
              1
            ],
            "details": "Develop a POST /api/subdomain/check endpoint that validates subdomain format (alphanumeric, 3-32 chars, no reserved words), checks uniqueness, and returns availability. Ensure server-side validation to prevent race conditions. Integrate this checker into the onboarding and settings UI for Pro plan users, providing real-time feedback. Restrict subdomain features to Pro users via feature flags.",
            "status": "pending",
            "testStrategy": "Test API with valid, invalid, and taken subdomains. Simulate concurrent requests to ensure atomicity. Verify UI provides real-time feedback and restricts access to Pro users.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Configure Vercel Wildcard Domains and Public Property Pages with Custom Branding",
            "description": "Set up wildcard domain routing and build public property pages that reflect developer branding.",
            "dependencies": [
              1,
              2
            ],
            "details": "Update Vercel project to add *.otoraport.pl as a wildcard domain. Configure Next.js middleware to extract subdomain from the host header and inject it into the request context. Create a public route (e.g., /[subdomain]) that fetches and displays the developer's public properties, applying SSR/ISR for SEO. Dynamically apply branding (logo, colors) using CSS variables or theming. Ensure pages are mobile-responsive, SEO-friendly, and protected against XSS/injection.",
            "status": "pending",
            "testStrategy": "Verify wildcard routing for various subdomains. Test public property pages for correct data, branding, and responsiveness. Check SEO tags and sitemap updates. Perform security testing for XSS and injection vulnerabilities.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on implement subdomain system for pro plan.",
        "updatedAt": "2025-10-09T08:28:09.643Z"
      },
      {
        "id": "62",
        "title": "Implement Custom Domains for Enterprise Plan",
        "description": "Enable Enterprise plan users to configure custom domains for their OTORAPORT sites, including DNS TXT record validation, Vercel domain API integration, setup instructions, and DNS propagation checking.",
        "details": "1. **Database Schema Update:**\n   - Add a `custom_domain` (VARCHAR, unique, nullable) column to the `developers` table via a migration. Enforce uniqueness and update RLS policies so only the owning developer can modify their custom domain.\n\n2. **Custom Domain Registration Flow:**\n   - Build a UI flow for Enterprise users to enter and request a custom domain (e.g., `www.example.com`).\n   - Validate domain format (RFC 1035 compliance, no reserved words, 3-64 chars).\n   - On submission, generate a DNS TXT record (e.g., `_otoraport-verification.example.com` with a random token) and instruct the user to add it to their DNS provider.\n\n3. **DNS TXT Record Validation:**\n   - Implement an API endpoint (`POST /api/custom-domain/verify`) that checks for the presence and correctness of the TXT record using a DNS lookup library (e.g., `dns.promises` in Node.js or a third-party API).\n   - On successful verification, mark the domain as verified in the database.\n\n4. **Vercel Domain API Integration:**\n   - Integrate with Vercel's Domains API to programmatically add the verified custom domain to the correct Vercel environment. Handle errors such as domain already in use, verification failures, or API rate limits.\n   - Support both apex domains (A record) and subdomains (CNAME record) as per Vercel's requirements[1].\n\n5. **Setup Instructions Page:**\n   - Create a dedicated setup page that guides users through the process: entering the domain, adding the TXT record, verifying, and updating DNS records (A/CNAME) for Vercel. Include troubleshooting tips for common DNS issues (e.g., propagation delays, misconfigured records).\n\n6. **DNS Propagation Checker:**\n   - Implement a DNS propagation checker that periodically polls for the required DNS records and displays status updates to the user. Use a low TTL recommendation for faster propagation[2].\n   - Optionally, integrate with third-party DNS propagation APIs for more robust global checking.\n\n7. **Security & Best Practices:**\n   - Ensure all domain operations are authenticated and scoped to the developer's account.\n   - Log all domain verification attempts and API interactions for auditability.\n   - Provide clear error messages and actionable feedback throughout the flow.\n\n8. **Documentation:**\n   - Update developer documentation with step-by-step instructions, supported domain formats, and troubleshooting guidance.\n\n**Technologies & Patterns:**\n- Use Supabase migrations for schema changes.\n- Use Vercel Domains API for domain management.\n- Use Node.js DNS libraries or third-party APIs for DNS lookups.\n- Follow best practices for DNS record validation and secure domain assignment.",
        "testStrategy": "1. **Database:**\n   - Verify the `custom_domain` column exists, is unique, and RLS policies are enforced.\n   - Attempt to assign duplicate custom domains and confirm rejection.\n\n2. **UI & Flow:**\n   - Test the setup instructions page for clarity and completeness.\n   - Simulate user entry of a valid domain and verify correct TXT record generation and instructions.\n\n3. **DNS Validation:**\n   - Add the TXT record to a test domain and verify the API correctly detects and validates it.\n   - Test with missing, incorrect, and delayed TXT records to ensure robust error handling.\n\n4. **Vercel Integration:**\n   - Add a verified domain via the API and confirm it appears in the Vercel dashboard and routes traffic correctly.\n   - Test apex and subdomain flows, including DNS record requirements (A/CNAME).\n\n5. **DNS Propagation Checker:**\n   - Simulate DNS propagation delays and verify the checker updates status accurately.\n   - Test with various DNS providers for compatibility.\n\n6. **Security:**\n   - Attempt unauthorized domain assignments and verify access controls.\n   - Review audit logs for completeness.\n\n7. **Documentation:**\n   - Review documentation for accuracy and completeness with a test user.",
        "status": "done",
        "dependencies": [
          "61"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Custom Domain Registration and DNS TXT Validation Flow",
            "description": "Develop the backend and frontend logic for Enterprise users to register custom domains, generate DNS TXT tokens, and validate domain ownership via DNS TXT record lookup.",
            "dependencies": [],
            "details": "Create a UI for domain entry with RFC 1035 validation. On submission, generate a unique DNS TXT token (e.g., _otoraport-verification.example.com) and display setup instructions. Implement an API endpoint to check for the TXT record using a DNS lookup library, marking the domain as verified upon successful detection. Ensure all operations are authenticated and scoped to the developer's account.",
            "status": "pending",
            "testStrategy": "Submit valid and invalid domains, verify correct token generation, and test DNS TXT record detection using both local and public DNS resolvers. Attempt verification before and after DNS propagation to ensure correct status handling.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Integrate Vercel Domain API and DNS Propagation Checker",
            "description": "Integrate with Vercel's Domains API to add verified custom domains and implement a DNS propagation checker to monitor DNS record status.",
            "dependencies": [
              1
            ],
            "details": "After domain verification, use Vercel's Domains API to add the domain to the appropriate environment, handling apex and subdomain cases. Implement a DNS propagation checker that periodically polls for required DNS records (A/CNAME) and updates the user on propagation status. Optionally, integrate with third-party DNS propagation APIs for global checks.",
            "status": "pending",
            "testStrategy": "Test adding both apex and subdomains to Vercel, simulate API errors (e.g., domain in use), and verify error handling. For the propagation checker, update DNS records and confirm status updates reflect actual propagation across multiple DNS servers.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Develop Setup Instructions Page and Update Documentation",
            "description": "Create a comprehensive setup instructions page for users and update developer documentation with step-by-step guidance and troubleshooting.",
            "dependencies": [
              1,
              2
            ],
            "details": "Build a dedicated setup page guiding users through domain entry, TXT record setup, verification, and DNS record updates for Vercel. Include troubleshooting tips for common DNS issues and propagation delays. Update developer documentation to reflect supported domain formats, flow steps, and error handling.",
            "status": "pending",
            "testStrategy": "Review the setup page for clarity and completeness. Have users follow the instructions and report any confusion or missing steps. Validate that documentation covers all supported scenarios and troubleshooting cases.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on implement custom domains for enterprise plan.",
        "updatedAt": "2025-10-09T09:17:40.440Z"
      },
      {
        "id": "63",
        "title": "Implement Advanced Analytics Dashboard for Enterprise",
        "description": "Create a dedicated /dashboard/analytics page for Enterprise users featuring advanced charts (price trends, occupancy, days to sell), competitor benchmarking, and export options for PDF and Excel.",
        "details": "1. **Requirements & Planning:**\n   - Define dashboard goals and KPIs in collaboration with stakeholders (e.g., price trends, occupancy rates, days to sell, competitor benchmarks)[2][3][7].\n   - Identify and integrate relevant data sources, including price history (from Task 56), property data, and competitor datasets.\n\n2. **Data Preparation:**\n   - Ensure data quality and consistency by cleaning and validating inputs from all sources[2][1].\n   - Aggregate and preprocess data for efficient querying and visualization (consider caching or using dedicated analytics tables for heavy computations).\n\n3. **Dashboard Design & UX:**\n   - Design a clear, intuitive layout prioritizing key metrics and actionable insights above the fold[4][5].\n   - Use interactive charts (e.g., line, bar, scatter) for price trends, occupancy, and days to sell, leveraging libraries such as Recharts or D3.js for advanced visuals.\n   - Implement competitor benchmarking with comparative charts and tables.\n   - Add filtering, sorting, and drill-down capabilities for deeper analysis[2][7].\n   - Ensure mobile responsiveness and accessibility.\n\n4. **Export Functionality:**\n   - Integrate PDF export using libraries like jsPDF or Puppeteer, ensuring charts and tables render accurately.\n   - Implement Excel export using libraries such as SheetJS, supporting both raw data and formatted tables.\n\n5. **Security & Access Control:**\n   - Restrict dashboard access to Enterprise users only, enforcing role-based access at both API and UI levels.\n   - Ensure sensitive data is encrypted in transit and at rest, and comply with relevant data privacy regulations (e.g., GDPR)[1].\n\n6. **Performance & Scalability:**\n   - Optimize data queries and chart rendering for large datasets.\n   - Monitor dashboard performance and schedule regular reviews for updates and improvements[1][2].\n\n7. **Documentation & Training:**\n   - Provide user documentation and onboarding materials for dashboard features and exports[1].\n\n**Best Practices:**\n- Focus on actionable insights and avoid cluttering the dashboard with unnecessary metrics[2][3][5].\n- Use storytelling techniques to present data in a way that supports decision-making[3][7].\n- Plan for iterative improvements based on user feedback and evolving business needs[2][1].",
        "testStrategy": "1. Verify that only Enterprise users can access /dashboard/analytics and all data is scoped correctly.\n2. Test each chart for accuracy, interactivity (filtering, sorting, drill-down), and correct rendering with sample and edge-case data.\n3. Validate competitor benchmarking calculations and visualizations against known datasets.\n4. Test PDF and Excel export features for completeness, formatting, and data integrity.\n5. Perform performance testing with large datasets to ensure acceptable load times and responsiveness.\n6. Conduct security audits for access control and data privacy compliance.\n7. Review documentation and onboarding materials for clarity and completeness.\n8. Gather user feedback and iterate on dashboard design and features.",
        "status": "done",
        "dependencies": [
          "56"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Implement Advanced Analytics Dashboard UI/UX",
            "description": "Create the /dashboard/analytics page layout for Enterprise users, focusing on advanced charts (price trends, occupancy, days to sell), competitor benchmarking, and interactive features.",
            "dependencies": [],
            "details": "Design a responsive dashboard using a clear hierarchy: place key metrics and actionable insights at the top left, group related charts into thematic sections, and ensure consistency in chart placement and labeling. Use interactive chart libraries (e.g., Recharts, D3.js) for advanced visuals, and implement filtering, sorting, and drill-down capabilities. Prioritize mobile responsiveness and accessibility throughout the design.",
            "status": "done",
            "testStrategy": "Test UI on multiple devices and screen sizes for responsiveness. Validate that all charts render correctly, are interactive, and display accurate data. Conduct usability testing with sample users to ensure intuitive navigation and information hierarchy.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T11:45:46.962Z"
          },
          {
            "id": 2,
            "title": "Integrate and Prepare Data for Analytics Visualizations",
            "description": "Aggregate, clean, and preprocess data from price history, property, and competitor sources to support efficient querying and visualization in the dashboard.",
            "dependencies": [
              1
            ],
            "details": "Connect to all required data sources, ensuring data quality and consistency through validation and cleaning routines. Aggregate and preprocess data for each metric (price trends, occupancy, days to sell, competitor benchmarks), considering caching or dedicated analytics tables for performance. Ensure data is scoped to Enterprise users and complies with privacy requirements.",
            "status": "done",
            "testStrategy": "Verify data accuracy by cross-checking dashboard outputs with source data. Test performance with large datasets to ensure fast load times. Confirm that only authorized Enterprise users can access relevant data.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T11:45:47.888Z"
          },
          {
            "id": 3,
            "title": "Implement Export Functionality for PDF and Excel",
            "description": "Enable exporting of dashboard charts and tables to PDF and Excel formats, ensuring accurate rendering and data formatting.",
            "dependencies": [
              2
            ],
            "details": "Integrate PDF export using libraries like jsPDF or Puppeteer, ensuring all charts and tables render as expected. Implement Excel export with SheetJS, supporting both raw data and formatted tables. Ensure export features are accessible from the dashboard UI and maintain data privacy and access controls.",
            "status": "done",
            "testStrategy": "Test export functions with various dashboard states and data volumes. Validate that exported files match on-screen data and formatting. Check that only authorized users can export data and that sensitive information is handled securely.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T11:45:48.858Z"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on implement advanced analytics dashboard for enterprise.",
        "updatedAt": "2025-10-09T11:45:48.858Z"
      },
      {
        "id": "64",
        "title": "Build Admin Panel - Property Management",
        "description": "Develop the /admin/properties page for administrators, featuring cross-developer property search, advanced filters, bulk actions (approve, reject, delete), and CSV export functionality.",
        "details": "1. **Page Structure & Access Control:**\n   - Implement the /admin/properties route, restricting access to admin users only using existing authentication and role-based access control patterns.\n   - Use a responsive, user-friendly UI framework (e.g., Radix UI, Material UI) to ensure intuitive navigation and accessibility across devices[4][2].\n\n2. **Property Search & Filtering:**\n   - Integrate a search bar supporting queries across all developers' properties (by address, property ID, or developer name).\n   - Add advanced filters: developer (dropdown, multi-select), status (using enums from Task 39), price range (min/max), and location (city, region, or geospatial input).\n   - Ensure filters are debounced and server-driven for scalability with large datasets.\n\n3. **Properties Table:**\n   - Display properties in a paginated, sortable table with columns: Property ID, Developer, Status (with StatusBadge from Task 39), Price, Location, and Actions.\n   - Support multi-row selection with checkboxes for bulk actions.\n\n4. **Bulk Actions:**\n   - Implement toolbar for bulk approve, reject, and delete actions.\n   - Use confirmation dialogs for destructive actions (reject, delete) and optimistic UI updates with error handling.\n   - Integrate with existing PATCH /api/properties/bulk endpoint for status updates (from Task 39); create new endpoints if needed for approve/reject/delete.\n\n5. **CSV Export:**\n   - Add export button to download filtered property data as CSV.\n   - Ensure exported data respects current filters and includes all visible columns.\n   - Use streaming or background job for large exports to avoid blocking UI.\n\n6. **Performance & Security:**\n   - Use server-side pagination and filtering to handle large property datasets efficiently.\n   - Enforce strict RLS policies to prevent unauthorized data access, even for admin users.\n   - Log all bulk actions for auditability.\n\n7. **UI/UX Best Practices:**\n   - Provide loading and empty states, error feedback, and accessible keyboard navigation.\n   - Ensure all actions are undoable where feasible (e.g., soft delete with restore option).\n   - Follow consistent design patterns with the rest of the admin dashboard.\n\n8. **Documentation:**\n   - Document API endpoints, UI components, and usage instructions for future maintainers.\n\n**Technologies:** Next.js/React, TypeScript, Radix UI or Material UI, Supabase/Postgres (with RLS), CSV export libraries (e.g., papaparse), and existing API infrastructure.",
        "testStrategy": "1. Verify only admin users can access /admin/properties and all data is visible across developers.\n2. Test property search and each filter (developer, status, price, location) for accuracy and performance with large datasets.\n3. Confirm properties table displays correct data, supports sorting, pagination, and multi-row selection.\n4. Execute bulk approve, reject, and delete actions; verify database updates, UI feedback, and error handling for partial failures.\n5. Test CSV export with various filters and large result sets; ensure exported data matches visible table data.\n6. Validate RLS policies prevent unauthorized access, even via direct API calls.\n7. Check audit logs for all bulk actions.\n8. Test accessibility (keyboard navigation, ARIA labels), responsive design, and loading/error/empty states.\n9. Review documentation for completeness and clarity.",
        "status": "done",
        "dependencies": [
          "39",
          "57"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Page Structure, Access Control, and Properties Table",
            "description": "Set up the /admin/properties route with admin-only access, and build the main properties table with pagination, sorting, and multi-row selection.",
            "dependencies": [],
            "details": "Use Next.js routing and existing authentication/role-based access control to restrict the page to admin users. Integrate a UI framework (Radix UI or Material UI) for responsive layout. Create a paginated, sortable table displaying Property ID, Developer, Status (with StatusBadge), Price, Location, and Actions. Support multi-row selection with checkboxes for bulk actions. Ensure loading, empty, and error states are handled.",
            "status": "done",
            "testStrategy": "Verify only admin users can access the page. Check that the table displays correct data, supports sorting and pagination, and allows multi-row selection. Test UI responsiveness and accessibility.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T16:26:18.698Z"
          },
          {
            "id": 2,
            "title": "Develop Property Search, Advanced Filters, and Bulk Actions",
            "description": "Add cross-developer property search, advanced filtering (developer, status, price, location), and implement bulk approve, reject, and delete actions with confirmation dialogs.",
            "dependencies": [
              1
            ],
            "details": "Integrate a debounced search bar and server-driven filters for developer (multi-select), status (enum), price range, and location. Connect filters to backend for scalability. Implement bulk action toolbar for approve, reject, and delete, using confirmation dialogs for destructive actions. Integrate with PATCH /api/properties/bulk and create new endpoints if needed. Provide optimistic UI updates and error handling.",
            "status": "done",
            "testStrategy": "Test search and each filter for accuracy and performance with large datasets. Verify bulk actions update property statuses correctly, show confirmation dialogs, and handle errors gracefully. Confirm audit logging for all bulk actions.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T16:26:19.629Z"
          },
          {
            "id": 3,
            "title": "Implement CSV Export, Performance, Security, and Documentation",
            "description": "Enable CSV export of filtered property data, enforce server-side pagination and RLS, and document API endpoints and UI components.",
            "dependencies": [
              2
            ],
            "details": "Add an export button to download filtered property data as CSV, ensuring all visible columns are included and large exports use streaming or background jobs. Enforce server-side pagination/filtering and strict RLS policies for security. Log all bulk actions. Document API endpoints, UI components, and usage instructions for maintainers.",
            "status": "done",
            "testStrategy": "Verify CSV export matches current filters and includes all columns. Test performance with large datasets. Confirm RLS prevents unauthorized access. Review documentation for completeness and clarity.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T16:26:20.581Z"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on build admin panel - property management.",
        "updatedAt": "2025-10-09T16:26:20.581Z"
      },
      {
        "id": "65",
        "title": "Build Admin Panel - Subscription Management Page with Revenue Dashboard and Manual Controls",
        "description": "Develop the /admin/subscriptions page featuring MRR/ARR revenue charts, a failed payments list, manual refund functionality via Stripe API, and manual upgrade/downgrade controls for admin users.",
        "details": "1. **Page Structure & Access:**\n   - Implement /admin/subscriptions route, accessible only to users with admin privileges (reuse or extend existing role-based access control middleware).\n   - Use a responsive layout with a sidebar for navigation and a main content area for subscription management features, following established admin panel UI/UX best practices[10][3].\n\n2. **Revenue Dashboard (MRR/ARR Charts):**\n   - Integrate a charting library (e.g., Chart.js or Recharts) to visualize Monthly Recurring Revenue (MRR) and Annual Recurring Revenue (ARR) trends over time.\n   - Fetch and aggregate subscription payment data from your backend (ensure endpoints provide time-series revenue data, grouped by month/year).\n   - Display key metrics (current MRR, ARR, active subscriptions count) as summary cards above the charts for quick insights[9][4].\n\n3. **Failed Payments List:**\n   - Display a paginated, filterable table of failed payment attempts, including customer name, subscription plan, failure reason, and timestamp.\n   - Fetch failed payment data from your backend, which should be synced with Stripe's payment_intent and invoice events (ensure webhook handling is robust).\n   - Provide search and filter options (by customer, date range, plan, status) for efficient admin workflows[3][1].\n\n4. **Manual Refund Button (Stripe API):**\n   - Add a 'Refund' action button to each eligible payment row (successful payments only, not failed ones).\n   - On click, open a confirmation modal; upon confirmation, call a secure backend endpoint that uses the Stripe API to create a refund for the selected payment (use idempotency keys and proper error handling as per Stripe best practices).\n   - Log all manual refund actions with admin user ID and timestamp for audit purposes.\n\n5. **Manual Upgrade/Downgrade Options:**\n   - For each active subscription, provide admin controls to change the user's plan (upgrade/downgrade) or adjust limits.\n   - On action, open a modal to select the new plan and confirm; trigger backend logic to update the subscription in Stripe and your database, ensuring proration and billing adjustments are handled correctly.\n   - Display current plan, limits, and next billing date for context.\n\n6. **Security & Audit:**\n   - Ensure all admin actions (refunds, plan changes) are logged with user, action, and timestamp.\n   - Validate all inputs and enforce strict backend authorization for all sensitive operations.\n\n7. **Testing & Error Handling:**\n   - Implement loading, error, and empty states for all data tables and charts.\n   - Use optimistic UI updates where appropriate, but always confirm backend success before finalizing state changes.\n\n8. **Documentation:**\n   - Document all new endpoints, admin workflows, and Stripe integration details for future maintainers.\n\n**Tech Stack Recommendations:**\n- Use React (with TypeScript) for UI, Next.js routing, and Tailwind CSS for styling.\n- Use Stripe Node.js SDK for backend payment/refund operations.\n- Chart.js or Recharts for data visualization.\n- Ensure all sensitive operations are performed server-side and exposed via secure API endpoints.\n\n**References:**\n- Stripe Admin Refunds: https://stripe.com/docs/refunds\n- Admin Panel Design: [10][9]\n- Subscription Management Patterns: [3][6][7]",
        "testStrategy": "1. Verify only admin users can access /admin/subscriptions; non-admins are redirected or shown an error.\n2. Confirm MRR/ARR charts display accurate, up-to-date data by cross-checking with Stripe dashboard and backend reports.\n3. Test failed payments list: simulate failed payments in Stripe, ensure they appear with correct details and filters work as expected.\n4. Test manual refund: trigger refund from admin panel, verify refund is processed in Stripe, status updates in UI, and audit log entry is created.\n5. Test manual upgrade/downgrade: change a user's plan from admin panel, verify changes in Stripe, database, and UI; ensure proration and billing adjustments are correct.\n6. Attempt all sensitive actions as a non-admin and confirm access is denied.\n7. Simulate backend/API errors for each action (refund, upgrade, downgrade) and verify user-friendly error messages and no data corruption.\n8. Review audit logs for all admin actions and confirm completeness and accuracy.\n9. Test on multiple devices and browsers for responsive layout and usability.",
        "status": "done",
        "dependencies": [
          "57"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Revenue Dashboard with MRR/ARR Charts and Summary Metrics",
            "description": "Develop the revenue dashboard section of the /admin/subscriptions page, featuring interactive charts for Monthly Recurring Revenue (MRR) and Annual Recurring Revenue (ARR), plus summary cards for key metrics.",
            "dependencies": [],
            "details": "Integrate a charting library (e.g., Chart.js or Recharts) to visualize MRR/ARR trends. Fetch and aggregate subscription payment data from the backend, ensuring endpoints provide time-series revenue data grouped by month/year. Display summary cards for current MRR, ARR, and active subscriptions count above the charts. Ensure responsive layout and admin-only access.",
            "status": "done",
            "testStrategy": "Cross-check chart data and summary metrics with Stripe dashboard and backend reports. Test loading, error, and empty states for charts and cards. Verify only admin users can access this section.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T12:35:28.668Z"
          },
          {
            "id": 2,
            "title": "Build Failed Payments List with Manual Refund Controls",
            "description": "Create a paginated, filterable table of failed payment attempts and add manual refund functionality for eligible payments using the Stripe API.",
            "dependencies": [
              1
            ],
            "details": "Fetch failed payment data from the backend, synced with Stripe payment_intent and invoice events. Display customer name, plan, failure reason, and timestamp. Add search and filter options (customer, date range, plan, status). For successful payments, add a 'Refund' button that opens a confirmation modal and triggers a secure backend endpoint to create a Stripe refund. Log all manual refund actions with admin user ID and timestamp.",
            "status": "done",
            "testStrategy": "Simulate failed payments in Stripe and verify table accuracy. Test refund flow: confirm modal, backend call, Stripe refund creation, and audit logging. Validate search/filter functionality and error handling.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T12:35:29.591Z"
          },
          {
            "id": 3,
            "title": "Implement Manual Upgrade/Downgrade Controls for Subscriptions",
            "description": "Add admin controls to upgrade or downgrade user subscription plans and adjust limits, ensuring correct proration and billing updates via Stripe and the backend.",
            "dependencies": [
              2
            ],
            "details": "For each active subscription, provide controls to change the user's plan or limits. On action, open a modal to select the new plan and confirm. Trigger backend logic to update the subscription in Stripe and the database, handling proration and billing adjustments. Display current plan, limits, and next billing date for context. Log all actions for audit purposes.",
            "status": "done",
            "testStrategy": "Test upgrade/downgrade flow: modal selection, backend update, Stripe subscription change, and proration accuracy. Confirm audit logging and UI updates. Validate error and loading states.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T12:35:31.134Z"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on build admin panel - subscription management page with revenue dashboard and manual controls.",
        "updatedAt": "2025-10-09T12:35:31.134Z"
      },
      {
        "id": "66",
        "title": "Implement Multi-Step Onboarding Wizard Component",
        "description": "Develop a multi-step onboarding wizard with steps for welcome/company info, logo upload, CSV upload with inline help, data verification preview, and endpoint testing, including skip and state persistence features.",
        "details": "Implement a React-based multi-step onboarding wizard using a robust stepper component (such as MUI Stepper, CoreUI Stepper, or a custom solution) to provide a clear, accessible, and responsive user experience[4][6][7].\n\n**Step Structure:**\n- Step 1: Welcome screen with company info form and logo upload (support drag-and-drop, preview, and validation for image type/size).\n- Step 2: CSV upload with inline contextual help (display sample CSV, validation errors, and tips for formatting).\n- Step 3: Data verification step showing a preview table of parsed CSV data, highlighting errors or warnings.\n- Step 4: Test endpoints step displaying dynamically generated XML/CSV/MD5 URLs for the user to test, with copy-to-clipboard and status indicators.\n\n**Features:**\n- Allow users to skip steps where appropriate (e.g., skip logo upload or CSV upload), with clear UI affordances.\n- Persist onboarding state in localStorage or sessionStorage to allow users to resume if they leave and return[2].\n- Save progress to the backend at each step (where applicable) to ensure data integrity and support multi-device onboarding.\n- Provide clear navigation (next, back, skip, finish), progress indicators, and validation feedback at each step.\n- Use a centralized schema (e.g., Zod or Yup) for form validation and type safety across steps[2].\n- Ensure accessibility (keyboard navigation, ARIA labels) and responsive design.\n- Integrate with existing authentication/session context to associate onboarding data with the correct user.\n\n**Technical Considerations:**\n- Use modular React components for each step, managed by a parent wizard controller.\n- Leverage existing UI libraries (e.g., shadcn/ui, MUI, or CoreUI) for stepper and form controls where possible[4][6][5].\n- For file uploads, use a secure upload endpoint and show upload progress.\n- For endpoint testing, fetch and display live status (e.g., HTTP 200/404) for each URL.\n- Ensure onboarding can be resumed after authentication or page reload, using both frontend and backend state.\n\n**Documentation:**\n- Document the onboarding flow, component structure, and state management approach for maintainability.",
        "testStrategy": "1. Manually test the onboarding wizard end-to-end: complete each step, skip optional steps, and verify correct navigation and data persistence.\n2. Refresh or close/reopen the browser mid-onboarding and confirm state is restored from storage.\n3. Upload various logo files (valid/invalid types, large/small sizes) and verify validation and preview.\n4. Upload valid and invalid CSV files; verify inline help, error messages, and preview accuracy.\n5. On the verification step, confirm that data is displayed as expected and errors are highlighted.\n6. On the endpoint test step, verify that all URLs are generated correctly, copy-to-clipboard works, and live status is displayed.\n7. Confirm that onboarding data is saved to the backend at each step and associated with the correct user.\n8. Test accessibility: navigate the wizard using keyboard only and verify ARIA compliance.\n9. Test on multiple devices and screen sizes for responsive behavior.\n10. Write automated tests for step navigation, validation, and state persistence.",
        "status": "done",
        "dependencies": [
          "50"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Implement Modular Step Components for Onboarding Wizard",
            "description": "Create individual React components for each onboarding step: welcome/company info with logo upload, CSV upload with inline help, data verification preview, and endpoint testing.",
            "dependencies": [],
            "details": "Develop modular React components for each step, ensuring each supports required features (e.g., drag-and-drop logo upload with preview and validation, CSV upload with sample and inline help, preview table with error highlighting, endpoint testing with live status and copy-to-clipboard). Use a centralized validation schema (Zod or Yup) for form validation and type safety. Ensure accessibility and responsive design for all components.",
            "status": "done",
            "testStrategy": "Unit test each step component for rendering, validation, and accessibility. Manually verify drag-and-drop, file preview, error handling, and endpoint status features.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T13:17:01.327Z"
          },
          {
            "id": 2,
            "title": "Implement Wizard Controller with Navigation, State Persistence, and Skip Logic",
            "description": "Build the parent wizard controller to manage step navigation, progress indicators, skip functionality, and state persistence using localStorage/sessionStorage and backend sync.",
            "dependencies": [
              1
            ],
            "details": "Integrate a robust stepper component (e.g., MUI Stepper, CoreUI Stepper, or custom) to manage step transitions, progress display, and navigation controls (next, back, skip, finish). Implement logic to allow skipping optional steps and persist onboarding state in localStorage/sessionStorage. Sync progress to the backend at each step for multi-device support. Ensure onboarding can be resumed after authentication or page reload.",
            "status": "done",
            "testStrategy": "End-to-end test the wizard: complete, skip, and resume onboarding; verify state restoration after reload; check backend sync. Automated tests for navigation and persistence logic.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T13:17:02.262Z"
          },
          {
            "id": 3,
            "title": "Document Onboarding Wizard Flow, Component Structure, and State Management",
            "description": "Create comprehensive documentation covering the onboarding flow, component architecture, validation schema, and state management approach.",
            "dependencies": [
              1,
              2
            ],
            "details": "Write detailed documentation explaining the onboarding wizard's step structure, component hierarchy, validation strategy, navigation logic, state persistence mechanisms, and backend integration. Include code samples, usage instructions, and accessibility considerations for maintainability.",
            "status": "done",
            "testStrategy": "Review documentation for completeness and clarity. Peer review to ensure technical accuracy and maintainability.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T13:17:03.188Z"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on implement multi-step onboarding wizard component.",
        "updatedAt": "2025-10-09T13:17:03.188Z"
      },
      {
        "id": "67",
        "title": "Build Comprehensive Help Center and Documentation System",
        "description": "Develop a /help page featuring a structured FAQ (20+ questions), video tutorials, API documentation for Enterprise users, and robust search functionality, following best practices for accessibility, maintainability, and user experience.",
        "details": "1. **Page Structure & Routing**: Create a dedicated /help route with a responsive layout. Organize content into clear sections: FAQ, Video Tutorials, API Documentation, and Search. Use a sidebar or tabbed navigation for easy access to each section.\n\n2. **FAQ Section**: Author at least 20 frequently asked questions based on support tickets, user feedback, and anticipated onboarding issues. Use a collapsible accordion UI for each question/answer pair. Structure content using pre-formatted templates (e.g., Introduction, Steps, Tips) for consistency[2][3]. Include cross-references to related articles or features where relevant.\n\n3. **Video Tutorials**: Embed or host short, focused video guides covering key workflows (e.g., uploading CSV, setting up endpoints, verifying XML). Provide concise written summaries and step-by-step instructions alongside each video for accessibility. Ensure all videos have captions and descriptive alt text[1][3].\n\n4. **API Documentation (Enterprise)**: Integrate interactive API documentation (e.g., Swagger UI or Redoc) for Enterprise endpoints. Clearly separate public and Enterprise-only documentation. Include code samples, authentication instructions, and example requests/responses. Keep documentation versioned and up-to-date with backend changes.\n\n5. **Search Functionality**: Implement full-text search across all help content (FAQ, tutorials, API docs). Use a performant search library (e.g., Algolia, Fuse.js) with instant results and highlighting. Ensure search is accessible via keyboard and screen readers[2].\n\n6. **Accessibility & Responsiveness**: Follow WCAG guidelines for color contrast, keyboard navigation, and semantic HTML. Ensure the help center is fully usable on mobile and desktop devices[1][2].\n\n7. **Feedback & Analytics**: Allow users to rate articles or leave feedback. Collect analytics on search queries and article views to identify gaps and improve content iteratively[2][3].\n\n8. **Collaboration & Maintenance**: Use a documentation tool or markdown-based system to enable team collaboration and version control. Establish a review process for technical accuracy and clarity before publishing. Schedule regular updates to keep documentation current with product changes[1][3].",
        "testStrategy": "1. Verify /help page loads correctly and is accessible on all major browsers and devices.\n2. Confirm FAQ section displays at least 20 well-structured questions with working expand/collapse and cross-references.\n3. Test video tutorials for playback, captions, and accompanying text instructions; check accessibility compliance.\n4. Validate API documentation renders correctly, is interactive, and matches backend endpoints; test code samples and authentication flows.\n5. Ensure search returns relevant results from all help content, supports keyboard navigation, and highlights matches.\n6. Use accessibility testing tools (e.g., axe, Lighthouse) to check for WCAG compliance.\n7. Submit feedback/rating on articles and verify data is collected and visible in analytics.\n8. Review documentation for clarity, accuracy, and up-to-date information with stakeholders before release.",
        "status": "done",
        "dependencies": [
          "57"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Implement Help Center Page Structure and Navigation",
            "description": "Create a dedicated /help route with a responsive layout, organizing content into clear sections (FAQ, Video Tutorials, API Documentation, Search) and implementing intuitive sidebar or tabbed navigation.",
            "dependencies": [],
            "details": "Develop the /help page using a modern frontend framework. Ensure the layout is responsive for mobile and desktop. Organize content into distinct sections with sidebar or tabbed navigation for easy access. Follow accessibility guidelines for color contrast, keyboard navigation, and semantic HTML. Maintain consistent branding and user-friendly interface.",
            "status": "done",
            "testStrategy": "Verify /help page loads correctly on all major browsers and devices. Test navigation for accessibility and responsiveness. Confirm each section is easily accessible via sidebar or tabs.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T13:51:07.469Z"
          },
          {
            "id": 2,
            "title": "Develop and Integrate FAQ, Video Tutorials, and API Documentation Sections",
            "description": "Author at least 20 FAQ entries, embed video tutorials with captions and summaries, and integrate interactive API documentation for Enterprise users, ensuring content consistency and accessibility.",
            "dependencies": [
              1
            ],
            "details": "Gather FAQ topics from support tickets and user feedback. Write questions and answers using pre-formatted templates for consistency. Implement collapsible accordion UI for FAQs. Embed or host video tutorials with captions, alt text, and written summaries. Integrate Swagger UI or Redoc for API documentation, separating public and Enterprise endpoints. Include code samples and authentication instructions. Ensure all content meets accessibility standards.",
            "status": "done",
            "testStrategy": "Confirm FAQ section displays at least 20 well-structured questions with working expand/collapse. Test video playback, captions, and accompanying text instructions. Verify API docs are interactive, versioned, and up-to-date.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T13:51:08.381Z"
          },
          {
            "id": 3,
            "title": "Implement Search, Feedback, Analytics, and Collaboration Features",
            "description": "Add full-text search across all help content, enable user feedback and analytics, and set up collaborative content management and review processes for ongoing maintenance.",
            "dependencies": [
              1,
              2
            ],
            "details": "Integrate a performant search library (e.g., Algolia, Fuse.js) for instant results and highlighting across FAQ, tutorials, and API docs. Ensure search is accessible via keyboard and screen readers. Allow users to rate articles or leave feedback. Collect analytics on search queries and article views. Use a documentation tool or markdown-based system for team collaboration and version control. Establish a review process for technical accuracy and schedule regular updates.",
            "status": "done",
            "testStrategy": "Test search functionality for speed, accuracy, and accessibility. Verify feedback and analytics collection. Confirm collaborative editing and review workflows are operational.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T13:51:09.277Z"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on build comprehensive help center and documentation system.",
        "updatedAt": "2025-10-09T13:51:09.277Z"
      },
      {
        "id": "68",
        "title": "Implement Audit Logging System with API and Dashboard Integration",
        "description": "Design and implement a robust audit logging system, including database schema, event capture, API endpoint, user dashboard, and admin cross-user log view.",
        "details": "1. **Database Schema**: Create an `audit_logs` table with columns: `id` (UUID, PK), `user_id` (FK), `action` (VARCHAR), `resource_type` (VARCHAR), `changes` (JSONB), `ip_address` (INET), `user_agent` (TEXT), and `timestamp` (TIMESTAMP, default NOW). Ensure append-only structure for immutability and consider indexing on `user_id`, `action`, and `timestamp` for efficient querying[1][2][3].\n\n2. **Event Capture**: Integrate audit logging into backend services to record key actions: login, upload, delete, and subscription changes. Use middleware or service hooks to intercept these events and write structured records to the audit_logs table. For actions involving data changes, serialize pre- and post-change states in the `changes` field as JSON[1][3].\n\n3. **API Endpoint**: Implement `GET /api/user/audit-logs` to return paginated, filtered audit log entries for the authenticated user. Support query parameters for date range, action type, and resource filtering. Ensure proper access control so users only see their own logs, while admins can query all logs.\n\n4. **User Dashboard Page**: Create `/dashboard/activity` page displaying the user's audit log entries in a sortable, filterable table. Include columns for action, resource, timestamp, IP, and user agent. Provide search and export (CSV/JSON) options.\n\n5. **Admin Panel Cross-User View**: Extend the admin panel to allow privileged users to view, filter, and search audit logs across all users. Implement advanced filtering (by user, action, resource, date) and export capabilities. Ensure strict access control and audit admin access to logs.\n\n6. **Security & Retention**: Enforce append-only writes at the database level (e.g., via RLS or triggers) and implement retention policies (e.g., auto-archive logs older than N months). Ensure sensitive data in logs is handled per compliance requirements[2][6][7].\n\n7. **Best Practices**: Use standardized JSON schema for log entries to ensure consistency and future extensibility[3]. Separate audit log storage from operational tables if performance impact is observed[2].\n\n**Tech Stack Recommendations**: PostgreSQL (with JSONB for changes), RESTful API (Next.js/Express), React (MUI DataGrid or similar for dashboard), RBAC for access control.",
        "testStrategy": "1. Verify audit_logs table schema and append-only constraints; attempt unauthorized modification and confirm rejection.\n2. Trigger each key action (login, upload, delete, subscription change) and confirm audit log entry is created with correct metadata.\n3. Test GET /api/user/audit-logs endpoint for authenticated users and admins; verify filtering, pagination, and access control.\n4. Manually review /dashboard/activity page for correct display, filtering, and export functionality.\n5. Test admin panel cross-user log view for advanced filtering and export; confirm only authorized admins can access.\n6. Simulate log retention policy and confirm archival/deletion of old records.\n7. Perform security review to ensure no sensitive data leakage and audit log integrity.",
        "status": "done",
        "dependencies": [
          "50"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Implement Audit Log Database Schema and Event Capture",
            "description": "Create the audit_logs table and integrate event capture into backend services to record key user actions.",
            "dependencies": [],
            "details": "Define the audit_logs table with columns for id (UUID), user_id (FK), action, resource_type, changes (JSONB), ip_address, user_agent, and timestamp. Ensure append-only structure for immutability and index key columns for efficient querying. Integrate middleware or service hooks to capture events such as login, upload, delete, and subscription changes, serializing pre- and post-change states in the changes field.",
            "status": "done",
            "testStrategy": "Verify schema creation and append-only constraints. Trigger each key action and confirm audit log entry is created with correct metadata.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T13:59:56.182Z"
          },
          {
            "id": 2,
            "title": "Develop API Endpoint for Audit Log Retrieval with Access Control",
            "description": "Implement a RESTful API endpoint to return paginated, filtered audit log entries for users and admins, enforcing strict access control.",
            "dependencies": [
              1
            ],
            "details": "Create GET /api/user/audit-logs endpoint supporting query parameters for date range, action type, and resource filtering. Ensure users only see their own logs, while admins can query all logs. Apply RBAC for access management and validate filtering and pagination logic.",
            "status": "done",
            "testStrategy": "Test endpoint with various filters and roles. Confirm users cannot access other users' logs and admins can view all logs. Validate pagination and filtering.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T13:59:57.111Z"
          },
          {
            "id": 3,
            "title": "Implement User Dashboard and Admin Panel for Audit Log Visualization",
            "description": "Build dashboard pages for users and admins to view, filter, search, and export audit logs, with advanced filtering and export capabilities for admins.",
            "dependencies": [
              2
            ],
            "details": "Create /dashboard/activity page for users to view their audit logs in a sortable, filterable table with columns for action, resource, timestamp, IP, and user agent. Add search and export (CSV/JSON) options. Extend admin panel to allow cross-user log viewing with advanced filtering and export, ensuring strict access control and logging of admin access.",
            "status": "done",
            "testStrategy": "Verify dashboard displays correct logs for users and admins. Test filtering, searching, and export features. Confirm access control and audit admin access to logs.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T13:59:58.008Z"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on implement audit logging system with api and dashboard integration.",
        "updatedAt": "2025-10-09T13:59:58.008Z"
      },
      {
        "id": "69",
        "title": "Implement Public System Status Page with Real-Time Health Monitoring and Incident History",
        "description": "Develop a public, unauthenticated /status page displaying real-time health of ministry endpoints, database metrics, Stripe API status, historical uptime (30 days), and incident history.",
        "details": "1. **Requirements & Planning:**\n   - Identify all critical systems to monitor: ministry endpoints (XML/CSV/MD5 uptime), database (latency, connection pool), Stripe API, and any other essential services.\n   - Define clear status indicators (e.g., operational, degraded, outage) and ensure consistent color-coding and iconography for quick recognition[3][4][6].\n\n2. **Health Check Implementation:**\n   - Build backend health check endpoints for each monitored service:\n     - For ministry endpoints, implement periodic HTTP(S) checks for XML/CSV/MD5 endpoints, capturing response time and status.\n     - For the database, measure query latency and connection pool stats (e.g., via a lightweight SELECT 1 and pool metrics).\n     - For Stripe, use their API status endpoint or perform a lightweight API call to verify connectivity and latency.\n   - Store health check results in a dedicated database table with timestamped entries for historical analysis.\n   - Schedule health checks using a background job (e.g., cron, serverless function, or queue worker) at a configurable interval (e.g., every 1-5 minutes).\n\n3. **Incident & Uptime Tracking:**\n   - Design an incident logging system: allow for manual or automated creation of incident records with timestamps, affected components, status, and resolution notes.\n   - Track uptime per component and aggregate for a 30-day rolling window. Calculate uptime percentages and store daily summaries for efficient chart rendering.\n\n4. **Frontend /status Page:**\n   - Build a public, unauthenticated /status route using the main frontend framework (e.g., Next.js/React).\n   - Display current status for each monitored component with clear, non-technical language[2][3][4].\n   - Render a historical uptime chart (last 30 days) using a charting library (e.g., Recharts, Chart.js, or similar), with tooltips and color-coded bars.\n   - List recent incidents with timestamps, affected systems, and resolution details for transparency.\n   - Ensure the page is mobile-friendly, accessible (WCAG 2.1 AA), and matches organization branding.\n\n5. **Best Practices & Resilience:**\n   - Host the status page independently from core infrastructure to ensure availability during outages[2][3].\n   - Automate status updates where possible, but allow for manual incident creation and updates.\n   - Document incident response procedures and ensure clear, human-readable updates are posted promptly during incidents[1][2][4].\n   - Regularly review and update monitored components and thresholds.\n\n6. **Security & Privacy:**\n   - Do not expose sensitive internal metrics or stack traces; only display high-level health and incident summaries.\n   - Ensure no authentication is required for public access, but restrict incident creation/editing to authorized staff.\n\n7. **Extensibility:**\n   - Architect the system to allow easy addition of new monitored services or metrics in the future.\n   - Consider integration with external monitoring tools (e.g., UptimeRobot, StatusGator) for enhanced reliability if needed.\n",
        "testStrategy": "1. Simulate outages and degraded performance for each monitored service (ministry endpoints, database, Stripe API) and verify that the /status page updates in real time with correct status indicators and clear, non-technical messaging.\n2. Confirm that the historical uptime chart accurately reflects simulated downtime and displays correct percentages for the last 30 days.\n3. Create and resolve incidents (both manually and via automated triggers) and verify that incident history is displayed chronologically with all required details.\n4. Test the /status page on multiple devices and browsers for responsiveness, accessibility (using tools like axe or Lighthouse), and branding consistency.\n5. Confirm that no sensitive information is leaked and that only authorized users can create or edit incidents.\n6. Perform load testing to ensure the status page remains available and performant during simulated high-traffic scenarios (e.g., major incident).\n7. Review logs and database entries to ensure health checks and incident records are stored and updated as expected.",
        "status": "done",
        "dependencies": [
          "50"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Real-Time Health Check Backend for All Monitored Services",
            "description": "Develop backend health check endpoints and scheduled jobs to monitor ministry endpoints, database metrics, and Stripe API status in real time.",
            "dependencies": [],
            "details": "Create periodic health check routines for each service (HTTP(S) checks for ministry endpoints, database latency/pool checks, Stripe API connectivity). Store results in a dedicated database table with timestamps for historical analysis. Schedule checks using cron or background workers at configurable intervals.",
            "status": "done",
            "testStrategy": "Simulate outages and degraded performance for each monitored service and verify health check results are correctly stored and updated in real time.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T14:29:51.873Z"
          },
          {
            "id": 2,
            "title": "Design and Build Public /status Page Frontend with Uptime and Incident History",
            "description": "Develop a public, unauthenticated /status page that displays current system health, historical uptime (30 days), and incident history with clear indicators and branding.",
            "dependencies": [
              1
            ],
            "details": "Use a frontend framework (e.g., Next.js/React) to render real-time status for each component, historical uptime charts, and incident logs. Ensure clear color-coded indicators, non-technical messaging, mobile responsiveness, accessibility (WCAG 2.1 AA), and organization branding. Integrate with backend health check and incident data.",
            "status": "done",
            "testStrategy": "Verify that the /status page updates in real time, displays accurate uptime charts, and lists incidents with correct details. Test on multiple devices for responsiveness and accessibility.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T14:29:52.804Z"
          },
          {
            "id": 3,
            "title": "Implement Incident Logging and Uptime Aggregation System",
            "description": "Create systems for manual/automated incident logging and aggregate uptime calculations for each monitored component over a 30-day rolling window.",
            "dependencies": [
              1
            ],
            "details": "Design a database schema for incident records (timestamps, affected components, status, resolution notes). Implement logic to calculate and store daily uptime summaries for efficient chart rendering. Allow authorized staff to create/edit incidents while keeping public access read-only.",
            "status": "done",
            "testStrategy": "Create and resolve incidents manually and via automation, then verify correct display and aggregation on the status page. Confirm uptime percentages and incident history accuracy.",
            "parentId": "undefined",
            "updatedAt": "2025-10-09T14:29:53.711Z"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on implement public system status page with real-time health monitoring and incident history.",
        "updatedAt": "2025-10-09T14:29:53.711Z"
      },
      {
        "id": "70",
        "title": "Performance Optimization and Caching Implementation",
        "description": "Implement Redis caching for ministry endpoints, enable ISR for public pages, optimize database queries, add Next.js image optimization, and achieve high Lighthouse scores.",
        "details": "1. **Redis Caching for Ministry Endpoints**: Integrate Redis as an in-memory cache for ministry endpoints serving XML, CSV, and MD5 responses. Use a centralized middleware (e.g., in `middlewares/redis.js`) to handle cache reads/writes, with cache keys based on endpoint and parameters. Set a TTL (Time To Live) of 60 seconds for these responses. Use the `node-redis` client, ensure robust error handling, and monitor cache hit/miss rates for tuning[1][2][4][7].\n\n2. **Incremental Static Regeneration (ISR) for Public Pages**: For all public-facing Next.js pages, implement ISR with a `revalidate` interval of 3600 seconds (1 hour). Ensure that page data is re-fetched and rebuilt in the background after the interval, providing users with up-to-date content while maintaining fast load times.\n\n3. **Database Query Optimization**: Audit all queries related to ministry endpoints and public pages. Add appropriate indexes (e.g., on frequently filtered columns, foreign keys) and refactor queries for efficient joins and minimal data transfer. Use query analysis tools (such as PostgreSQL's `EXPLAIN ANALYZE`) to identify bottlenecks and verify improvements.\n\n4. **Next.js Image Optimization**: Refactor all image usage in public and dashboard pages to use the Next.js `<Image>` component. Configure image domains, enable AVIF/WebP formats, and set appropriate sizes and priorities for above-the-fold images. Leverage built-in lazy loading and responsive sizing for best performance.\n\n5. **Lighthouse Audit and Remediation**: Run Lighthouse audits on key public and dashboard pages. Address all issues to achieve at least Performance 90+, Accessibility 95+, Best Practices 90+, and SEO 95+. This may involve optimizing asset delivery, reducing unused JavaScript/CSS, improving ARIA/alt attributes, and ensuring semantic HTML.\n\n**Best Practices**:\n- Use environment variables for Redis connection configuration.\n- Ensure cache invalidation on relevant data updates.\n- Monitor Redis and database performance in production.\n- Document caching and ISR strategies for future maintainers.",
        "testStrategy": "1. For Redis caching, hit ministry endpoints repeatedly and verify cache hits/misses using Redis CLI or logs; confirm cache expires after 60s and updates on data change.\n2. For ISR, update backend data and confirm public pages reflect changes after revalidation interval (3600s) without full redeploy.\n3. Use database query logs and `EXPLAIN ANALYZE` to confirm indexes are used and query times are reduced; test endpoints under load.\n4. Run Lighthouse audits on public and dashboard pages, iteratively fix issues, and confirm target scores are met.\n5. Manually and automatically test image loading, responsiveness, and format negotiation on various devices and network conditions.",
        "status": "done",
        "dependencies": [
          "52",
          "54",
          "61",
          "66",
          "68"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Redis Caching Middleware for Ministry Endpoints",
            "description": "Integrate Redis as an in-memory cache for ministry endpoints serving XML, CSV, and MD5 responses using a centralized middleware.",
            "dependencies": [],
            "details": "Create a middleware (e.g., middlewares/redis.js) that intercepts requests to ministry endpoints, checks for cached responses in Redis using keys based on endpoint and parameters, and serves cached data if available. Use the node-redis client, set a TTL of 60 seconds for cached entries, and ensure robust error handling. Monitor cache hit/miss rates for tuning and use environment variables for Redis configuration.",
            "status": "pending",
            "testStrategy": "Repeatedly hit ministry endpoints and verify cache hits/misses using Redis CLI or logs. Confirm cache expires after 60 seconds and updates on data change.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Enable Incremental Static Regeneration (ISR) for Public Pages",
            "description": "Configure ISR for all public-facing Next.js pages to ensure up-to-date content and fast load times.",
            "dependencies": [
              1
            ],
            "details": "Set up ISR in Next.js by specifying a revalidate interval of 3600 seconds (1 hour) for public pages. Ensure that page data is re-fetched and rebuilt in the background after the interval. Document the ISR strategy for maintainers and verify that updates to backend data are reflected after revalidation.",
            "status": "pending",
            "testStrategy": "Update backend data and confirm public pages reflect changes after the revalidation interval without requiring a full redeploy.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Audit and Optimize Database Queries for Cached and ISR Endpoints",
            "description": "Review and optimize all database queries related to ministry endpoints and public pages for performance.",
            "dependencies": [
              1,
              2
            ],
            "details": "Audit queries for endpoints using Redis caching and ISR. Add indexes to frequently filtered columns and foreign keys, refactor queries for efficient joins and minimal data transfer, and use query analysis tools (e.g., PostgreSQL's EXPLAIN ANALYZE) to identify bottlenecks. Monitor database performance and document optimization strategies.",
            "status": "pending",
            "testStrategy": "Run query analysis before and after optimization, verify improved query times, and ensure no regressions in endpoint performance.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 3,
        "expansionPrompt": "Break down this task with a focus on performance optimization and caching implementation.",
        "updatedAt": "2025-10-09T16:44:54.086Z"
      },
      {
        "id": "71",
        "title": "Comprehensive Rebrand from otoraport.pl to raportowaniecenmieszkan.pl Across Codebase and Infrastructure",
        "description": "Update all domain references, email addresses, branding assets, documentation, and deployment configurations to reflect the new brand raportowaniecenmieszkan.pl throughout the entire codebase and supporting systems.",
        "details": "1. **Domain and URL Updates:**\n   - Search and replace all instances of 'otoraport.pl' with 'raportowaniecenmieszkan.pl' in code, configuration files, environment variables, documentation, and deployment scripts.\n   - Update all hardcoded URLs, API endpoints, and callback URLs to use the new domain.\n   - Register and configure the new domain with DNS providers and hosting platforms (e.g., Vercel), ensuring SSL certificates are updated and active.\n   - Implement 301 redirects from old URLs to new URLs to preserve SEO and user experience[3][7].\n\n2. **Email Address and System References:**\n   - Update all system-generated email addresses (e.g., noreply@otoraport.pl → noreply@raportowaniecenmieszkan.pl) in notification templates, authentication flows, and contact forms.\n   - Change email sender domains in transactional email services (e.g., SendGrid, Mailgun) and update SPF/DKIM records for deliverability.\n\n3. **Branding and Visual Assets:**\n   - Replace all logos, favicons, and brand imagery with new assets reflecting the updated brand identity.\n   - Update color palettes, typography, and design tokens in the codebase and style guides.\n   - Revise marketing collateral, email signatures, and social media profile images as needed[1][2][4].\n\n4. **Documentation and Help Center:**\n   - Update all internal and external documentation, including README files, API docs, onboarding guides, and help center articles, to reference the new brand and domain.\n   - Revise screenshots and instructional videos to reflect new branding.\n\n5. **Deployment and Configuration:**\n   - Update deployment pipelines, environment variables, and CI/CD scripts to use the new domain.\n   - Ensure all integrations (e.g., Stripe, ministry endpoints, analytics) reference the correct domain and branding.\n   - Review and update custom domain/subdomain logic to support the new brand, coordinating with related tasks for Pro and Enterprise plans.\n\n6. **Communication and Announcement:**\n   - Prepare a rebranding announcement for users, partners, and stakeholders via email, blog post, and social media.\n   - Create an FAQ page addressing the rebrand, transition timeline, and impact on users[1][4].\n\n7. **Quality Assurance:**\n   - Conduct a thorough audit using automated tools (e.g., grep, regex search, link checkers) and manual review to ensure no references to the old brand remain.\n   - Establish a review and approval process for all changes before deployment.\n\n**Best Practices:**\n- Use automated scripts for bulk search-and-replace operations to minimize manual errors.\n- Maintain a backup and rollback plan in case of unforeseen issues during deployment.\n- Communicate changes proactively to minimize user confusion and support requests.\n- Coordinate with legal and administrative teams to ensure compliance with business registrations and trademarks[1][3][6].",
        "testStrategy": "1. Perform a full-text search across the codebase, documentation, and configuration files to confirm all instances of 'otoraport.pl' have been replaced.\n2. Deploy to a staging environment and verify:\n   - All URLs, endpoints, and email addresses use the new domain.\n   - Branding assets (logos, colors, typography) are updated throughout the UI and emails.\n   - Documentation and help center content reflect the new brand.\n   - All redirects from old URLs function correctly (301 status, correct destination).\n   - Transactional and notification emails are sent from the new domain and pass SPF/DKIM checks.\n   - Integrations (Stripe, ministry endpoints, analytics) operate correctly with the new domain.\n3. Use link checkers and automated tests to identify any broken links or missed references.\n4. Review deployment logs and CI/CD output for errors related to domain or branding changes.\n5. Solicit feedback from internal stakeholders and a pilot group of users to confirm the rebrand is complete and consistent.\n6. Monitor analytics and support channels for issues post-launch.",
        "status": "in-progress",
        "dependencies": [
          "61",
          "62",
          "67"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Audit and Inventory All Brand References and Assets",
            "description": "Conduct a comprehensive audit to identify every instance of 'otoraport.pl' and related branding across code, documentation, infrastructure, and marketing materials.",
            "dependencies": [],
            "details": "Use automated tools (e.g., grep, regex search) and manual review to catalog all domain references, email addresses, visual assets, documentation, deployment scripts, and third-party integrations that reference the old brand. Document findings in a shared inventory for tracking.",
            "status": "pending",
            "testStrategy": "Verify completeness by cross-referencing audit results with all code repositories, documentation folders, and asset libraries. Spot-check random files and assets to ensure no references are missed.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Update Codebase, Configuration, and Infrastructure for New Domain",
            "description": "Replace all instances of 'otoraport.pl' with 'raportowaniecenmieszkan.pl' in code, configuration files, environment variables, and deployment scripts. Register and configure the new domain, update DNS, SSL, and set up 301 redirects.",
            "dependencies": [
              1
            ],
            "details": "Perform bulk search-and-replace operations in code and configuration files. Update hardcoded URLs, API endpoints, callback URLs, and environment variables. Register the new domain, configure DNS and SSL certificates, and implement 301 redirects from old URLs to new ones. Update deployment pipelines and CI/CD scripts to use the new domain.",
            "status": "pending",
            "testStrategy": "Deploy to a staging environment and verify all URLs, endpoints, and redirects function correctly. Use automated link checkers and manual testing to confirm no broken links or references remain.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Update Email Addresses, Sender Domains, and System References",
            "description": "Change all system-generated email addresses and sender domains to use the new brand. Update transactional email services and authentication flows accordingly.",
            "dependencies": [
              1
            ],
            "details": "Replace all instances of old email addresses (e.g., noreply@otoraport.pl) with new ones in notification templates, authentication flows, and contact forms. Update sender domains in services like SendGrid or Mailgun, and revise SPF/DKIM records for deliverability. Test email flows to ensure correct sender information.",
            "status": "pending",
            "testStrategy": "Send test emails from all system flows and verify correct sender addresses and domain authentication (SPF/DKIM). Check email deliverability and spam scores.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Replace Branding Assets and Update Visual Identity",
            "description": "Swap out all logos, favicons, and brand imagery for new assets. Update color palettes, typography, and design tokens in the codebase and style guides.",
            "dependencies": [
              1
            ],
            "details": "Replace all visual assets in the codebase, documentation, and marketing collateral with new versions reflecting the updated brand. Update style guides, design tokens, and UI components. Revise email signatures, social media profile images, and marketing materials as needed.",
            "status": "pending",
            "testStrategy": "Visually inspect all user-facing pages, emails, and collateral to confirm new branding is consistently applied. Use automated screenshot comparison tools where possible.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Revise Documentation, Help Center, and Communication Materials",
            "description": "Update all internal and external documentation, help center articles, onboarding guides, and communication templates to reference the new brand and domain.",
            "dependencies": [
              2,
              3,
              4
            ],
            "details": "Edit README files, API docs, onboarding guides, and help center content to reflect the new brand. Update screenshots and instructional videos. Prepare and distribute rebranding announcements and an FAQ for users, partners, and stakeholders.",
            "status": "pending",
            "testStrategy": "Review all documentation and help center articles for accuracy and completeness. Confirm that all screenshots and videos display the new branding. Validate that communication materials are distributed to all intended audiences.",
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2025-10-09T17:24:19.545Z"
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2025-10-09T17:24:19.546Z",
      "taskCount": 36,
      "completedCount": 34,
      "tags": [
        "master"
      ]
    }
  }
}